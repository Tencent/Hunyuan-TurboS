@misc{gpt4o,
  title = {Hello {GPT-4o}},
  author = {{OpenAI}},
  url = {https://openai.com/index/hello-gpt-4o/},
  year = {2024}
}


@article{hoskin1996,
    title={The ``awful idea of accountability'': Inscribing people into the measurement of objects},
    author={Hoskin, Keith},
    year={1996},
    editor={Rolland Munro and Jan Mouritsen},
    journal={Accountability: Power, ethos and the technologies of managing}
}

@misc{Athene2024,
    title = {Athene-70B: Redefining the Boundaries of Post-Training for Open Models},
    url = {https://nexusflow.ai/blogs/athene},
    author = {Frick, Evan and Jin, Peter and Li, Tianle and Ganesan, Karthik and Zhang, Jian and Jiao, Jiantao and Zhu, Banghua},    
    month = {July},
    year = {2024}
}
@article{Wang2024HelpSteer2PreferenceCR,
  title={{HelpSteer2-Preference}: Complementing Ratings with Preferences},
  author={Zhilin Wang and Alexander Bukharin and Olivier Delalleau and Daniel Egert and Gerald Shen and Jiaqi Zeng and Oleksii Kuchaiev and Yi Dong},
  journal={CoRR},
  year={2024},
  volume={abs/2410.01257}
}

@article{Adler2024Nemotron43T,
  title={Nemotron-4 {340B} Technical Report},
  author={Bo Adler and Niket Agarwal and Ashwath Aithal and Dong H. Anh and Pallab Bhattacharya and Annika Brundyn and Jared Casper and Bryan Catanzaro and Sharon Clay and Jonathan Cohen and Sirshak Das and Ayush Dattagupta and Olivier Delalleau and Leon Derczynski and Yi Dong and Daniel Egert and Ellie Evans and Aleksander Ficek and Denys Fridman and Shaona Ghosh and Boris Ginsburg and Igor Gitman and Tomasz Grzegorzek and Robert Hero and Jining Huang and Vibhu Jawa and Joseph Jennings and Aastha Jhunjhunwala and John Kamalu and Sadaf Khan and Oleksii Kuchaiev and Patrick LeGresley and Hui Li and Jiwei Liu and Zihan Liu and Eileen Peters Long and Ameya Mahabaleshwarkar and Somshubra Majumdar and James Maki and Miguel Martinez and Maer Rodrigues de Melo and Ivan Moshkov and Deepak Narayanan and Sean Narenthiran and Jesus Navarro and Phong Nguyen and Osvald Nitski and Vahid Noroozi and Guruprasad Nutheti and Christopher Parisien and Jupinder Parmar and Mostofa Patwary and Krzysztof Pawelec and Wei Ping and Shrimai Prabhumoye and Rajarshi Roy and Trisha Saar and Vasanth Rao Naik Sabavat and Sanjeev Satheesh and Jane Polak Scowcroft and Jason D. Sewall and Pavel Shamis and Gerald Shen and Mohammad Shoeybi and Dave Sizer and Misha Smelyanskiy and Felipe Soares and Makesh Narsimhan Sreedhar and Dan Su and Sandeep Subramanian and Shengyang Sun and Shubham Toshniwal and Hao Wang and Zhilin Wang and Jiaxuan You and Jiaqi Zeng and Jimmy Zhang and Jing Zhang and Vivienne Zhang and Yian Zhang and Chen Zhu},
  journal={CoRR},
  year={2024},
  volume={abs/2406.11704}
}
@article{Frick2024HowTE,
  title={How to Evaluate Reward Models for {RLHF}},
  author={Evan Frick and Tianle Li and Connor Chen and Wei-Lin Chiang and Anastasios Nikolas Angelopoulos and Jiantao Jiao and Banghua Zhu and Joseph E. Gonzalez and Ion Stoica},
  journal={CoRR},
  year={2024},
  volume={abs/2410.14872}
}
@article{Zhou2024RMBCB,
  title={{RMB}: Comprehensively Benchmarking Reward Models in {LLM} Alignment},
  author={Enyu Zhou and Guodong Zheng and Bing Wang and Zhiheng Xi and Shihan Dou and Rong Bao and Wei Shen and Limao Xiong and Jessica Fan and Yurong Mou and Rui Zheng and Tao Gui and Qi Zhang and Xuanjing Huang},
  journal={CoRR},
  year={2024},
  volume={abs/2410.09893}
}
@article{Lambert2024RewardBenchER,
  title={{RewardBench}: Evaluating Reward Models for Language Modeling},
  author={Nathan Lambert and Valentina Pyatkin and Jacob Daniel Morrison and Lester James Validad Miranda and Bill Yuchen Lin and Khyathi Raghavi Chandu and Nouha Dziri and Sachin Kumar and Tom Zick and Yejin Choi and Noah A. Smith and Hanna Hajishirzi},
  journal={CoRR},
  year={2024},
  volume={abs/2403.13787}
}

@article{palm,
  title={{PaLM}: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={CoRR},
  volume={abs/2204.02311},
  year={2022}
}

@article{yang2024evaluating,
  title={Evaluating and Aligning CodeLLMs on Human Preference},
  author={Yang, Jian and Yang, Jiaxi and Jin, Ke and Miao, Yibo and Zhang, Lei and Yang, Liqun and Cui, Zeyu and Zhang, Yichang and Hui, Binyuan and Lin, Junyang},
  journal={CoRR},
  volume={abs/2412.05210},
  year={2024}
}

@article{deepseekmath,
  author       = {Zhihong Shao and
                  Peiyi Wang and
                  Qihao Zhu and
                  Runxin Xu and
                  Junxiao Song and
                  Mingchuan Zhang and
                  Y. K. Li and
                  Y. Wu and
                  Daya Guo},
  title        = {DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open
                  Language Models},
  journal      = {CoRR},
  volume       = {abs/2402.03300},
  year         = {2024}
}

@article{wang2024secrets,
  title={Secrets of {RLHF} in large language models Part {II}: Reward modeling},
  author={Wang, Binghai and Zheng, Rui and Chen, Lu and Liu, Yan and Dou, Shihan and Huang, Caishuang and Shen, Wei and Jin, Senjie and Zhou, Enyu and Shi, Chenyu and others},
  journal={CoRR},
  volume={abs/2401.06080},
  year={2024}
}

@article{dou2024multi,
  title={Multi-Programming Language Sandbox for LLMs},
  author={Dou, Shihan and Zhang, Jiazheng and Zang, Jianxiang and Tao, Yunbo and Jia, Haoxiang and Liu, Shichun and Yang, Yuming and Wu, Shenxi and Zhang, Shaoqing and Wu, Muling and others},
  journal={CoRR},
  volume={abs/2410.23074},
  year={2024}
}


@article{quan2024language,
  title={Language Models Can Self-Lengthen to Generate Long Texts},
  author={Quan, Shanghaoran and Tang, Tianyi and Yu, Bowen and Yang, An and Liu, Dayiheng and Gao, Bofei and Tu, Jianhong and Zhang, Yichang and Zhou, Jingren and Lin, Junyang},
  journal={CoRR},
  volume={abs/2410.23933},
  year={2024},
  archivePrefix={arXiv},
  eprint={2410.23933},
  primaryClass={cs.CL}
}


@article{xiang2024aligning,
  title={Aligning Large Language Models via Self-Steering Optimization},
  author={Xiang, Hao and Yu, Bowen and Lin, Hongyu and Lu, Keming and Lu, Yaojie and Han, Xianpei and Sun, Le and Zhou, Jingren and Lin, Junyang},
  journal={CoRR},
  volume={abs/2410.17131},
  year={2024}
}

@article{palm2,
  title={{PaLM} 2 technical report},
  author={Anil, Rohan and Dai, Andrew M and Firat, Orhan and Johnson, Melvin and Lepikhin, Dmitry and Passos, Alexandre and Shakeri, Siamak and Taropa, Emanuel and Bailey, Paige and Chen, Zhifeng and others},
  journal={CoRR},
  volume={abs/2305.10403},
  year={2023}
}

@article{qwen2,
  author       = {An Yang and
                  Baosong Yang and
                  Binyuan Hui and
                  Bo Zheng and
                  Bowen Yu and
                  Chang Zhou and
                  Chengpeng Li and
                  Chengyuan Li and
                  Dayiheng Liu and
                  Fei Huang and
                  Guanting Dong and
                  Haoran Wei and
                  Huan Lin and
                  Jialong Tang and
                  Jialin Wang and
                  Jian Yang and
                  Jianhong Tu and
                  Jianwei Zhang and
                  Jianxin Ma and
                  Jianxin Yang and
                  Jin Xu and
                  Jingren Zhou and
                  Jinze Bai and
                  Jinzheng He and
                  Junyang Lin and
                  Kai Dang and
                  Keming Lu and
                  Keqin Chen and
                  Kexin Yang and
                  Mei Li and
                  Mingfeng Xue and
                  Na Ni and
                  Pei Zhang and
                  Peng Wang and
                  Ru Peng and
                  Rui Men and
                  Ruize Gao and
                  Runji Lin and
                  Shijie Wang and
                  Shuai Bai and
                  Sinan Tan and
                  Tianhang Zhu and
                  Tianhao Li and
                  Tianyu Liu and
                  Wenbin Ge and
                  Xiaodong Deng and
                  Xiaohuan Zhou and
                  Xingzhang Ren and
                  Xinyu Zhang and
                  Xipin Wei and
                  Xuancheng Ren and
                  Xuejing Liu and
                  Yang Fan and
                  Yang Yao and
                  Yichang Zhang and
                  Yu Wan and
                  Yunfei Chu and
                  Yuqiong Liu and
                  Zeyu Cui and
                  Zhenru Zhang and
                  Zhifang Guo and
                  Zhihao Fan},
  title        = {Qwen2 Technical Report},
  journal      = {CoRR},
  volume       = {abs/2407.10671},
  year         = {2024}
}

@article{yuan2023scaling,
  author       = {Zheng Yuan and
                  Hongyi Yuan and
                  Chengpeng Li and
                  Guanting Dong and
                  Chuanqi Tan and
                  Chang Zhou},
  title        = {Scaling Relationship on Learning Mathematical Reasoning with Large
                  Language Models},
  journal      = {CoRR},
  volume       = {abs/2308.01825},
  year         = {2023}
}

@misc{qwq,
  title={{QwQ}: Reflect deeply on the boundaries of the unknown},
  author={{Qwen Team}},
  year={2024},
  url={https://qwenlm.github.io/blog/qwq-32b-preview/}
}

@inproceedings{rafailov2024direct,
  author       = {Rafael Rafailov and
                  Archit Sharma and
                  Eric Mitchell and
                  Christopher D. Manning and
                  Stefano Ermon and
                  Chelsea Finn},
  title        = {Direct Preference Optimization: Your Language Model is Secretly a
                  Reward Model},
  booktitle    = {NeurIPS},
  year         = {2023}
}

@article{lu2024online,
  author       = {Keming Lu and
                  Bowen Yu and
                  Fei Huang and
                  Yang Fan and
                  Runji Lin and
                  Chang Zhou},
  title        = {Online Merging Optimizers for Boosting Rewards and Mitigating Tax
                  in Alignment},
  journal      = {CoRR},
  volume       = {abs/2405.17931},
  year         = {2024}
}

@article{bai2022constitutional,
author       = {Yuntao Bai and
                  Saurav Kadavath and
                  Sandipan Kundu and
                  Amanda Askell and
                  Jackson Kernion and
                  Andy Jones and
                  Anna Chen and
                  Anna Goldie and
                  Azalia Mirhoseini and
                  Cameron McKinnon and
                  Carol Chen and
                  Catherine Olsson and
                  Christopher Olah and
                  Danny Hernandez and
                  Dawn Drain and
                  Deep Ganguli and
                  Dustin Li and
                  Eli Tran{-}Johnson and
                  Ethan Perez and
                  Jamie Kerr and
                  Jared Mueller and
                  Jeffrey Ladish and
                  Joshua Landau and
                  Kamal Ndousse and
                  Kamile Lukosiute and
                  Liane Lovitt and
                  Michael Sellitto and
                  Nelson Elhage and
                  Nicholas Schiefer and
                  Noem{\'{\i}} Mercado and
                  Nova DasSarma and
                  Robert Lasenby and
                  Robin Larson and
                  Sam Ringer and
                  Scott Johnston and
                  Shauna Kravec and
                  Sheer El Showk and
                  Stanislav Fort and
                  Tamera Lanham and
                  Timothy Telleen{-}Lawton and
                  Tom Conerly and
                  Tom Henighan and
                  Tristan Hume and
                  Samuel R. Bowman and
                  Zac Hatfield{-}Dodds and
                  Ben Mann and
                  Dario Amodei and
                  Nicholas Joseph and
                  Sam McCandlish and
                  Tom Brown and
                  Jared Kaplan},
  title        = {Constitutional {AI}: Harmlessness from {AI} Feedback},
  journal      = {CoRR},
  volume       = {abs/2212.08073},
  year         = {2022}
}

@article{cao2024towards,
  author       = {Boxi Cao and
                  Keming Lu and
                  Xinyu Lu and
                  Jiawei Chen and
                  Mengjie Ren and
                  Hao Xiang and
                  Peilin Liu and
                  Yaojie Lu and
                  Ben He and
                  Xianpei Han and
                  Le Sun and
                  Hongyu Lin and
                  Bowen Yu},
  title        = {Towards Scalable Automated Alignment of {LLMs}: A Survey},
  journal      = {CoRR},
  volume       = {abs/2406.01252},
  year         = {2024}
}

@article{lu2024large,
  author       = {Keming Lu and
                  Bowen Yu and
                  Chang Zhou and
                  Jingren Zhou},
  title        = {Large Language Models are Superpositions of All Characters: Attaining
                  Arbitrary Role-play via Self-Alignment},
  journal      = {CoRR},
  volume       = {abs/2401.12474},
  year         = {2024}
}

@article{dong2024autoif,
  title={Self-play with Execution Feedback: Improving Instruction-following Capabilities of Large Language Models},
  author={Dong, Guanting and Lu, Keming and Li, Chengpeng and Xia, Tingyu and Yu, Bowen and Zhou, Chang and Zhou, Jingren},
  journal={CoRR},
  volume={abs/2406.13542},
  year={2024}
}

@article{ext5,
  title={{ExT5}: Towards extreme multi-task scaling for transfer learning},
  author={Aribandi, Vamsi and Tay, Yi and Schuster, Tal and Rao, Jinfeng and Zheng, Huaixiu Steven and Mehta, Sanket Vaibhav and Zhuang, Honglei and Tran, Vinh Q and Bahri, Dara and Ni, Jianmo and others},
  journal={CoRR},
  volume={abs/2111.10952},
  year={2021}
}

@article{pmmeval,
  title={{P-MMEval}: A Parallel Multilingual Multitask Benchmark for Consistent Evaluation of {LLMs}},
  author={Zhang, Yidan and Deng, Boyi and Wan, Yu and Yang, Baosong and Wei, Haoran and Huang, Fei and Yu, Bowen and Lin, Junyang and Zhou, Jingren},
  journal={CoRR},
  volume={abs/2411.09116},
  year={2024}
}

@article{dong2023abilities,
  author       = {Guanting Dong and
                  Hongyi Yuan and
                  Keming Lu and
                  Chengpeng Li and
                  Mingfeng Xue and
                  Dayiheng Liu and
                  Wei Wang and
                  Zheng Yuan and
                  Chang Zhou and
                  Jingren Zhou},
  title        = {How Abilities in Large Language Models are Affected by Supervised
                  Fine-tuning Data Composition},
  journal      = {CoRR},
  volume       = {abs/2310.05492},
  year         = {2023}
}

@inproceedings{zhao2024tree,
  author       = {Yingxiu Zhao and
                  Bowen Yu and
                  Binyuan Hui and
                  Haiyang Yu and
                  Minghao Li and
                  Fei Huang and
                  Nevin L. Zhang and
                  Yongbin Li},
  title        = {{Tree-Instruct}: {A} Preliminary Study of the Intrinsic Relationship
                  between Complexity and Alignment},
  booktitle    = {{LREC/COLING}},
  pages        = {16776--16789},
  publisher    = {{ELRA} and {ICCL}},
  year         = {2024}
}

@inproceedings{lu2023instag,
  title={\#{InsTag}: Instruction Tagging for Analyzing Supervised Fine-tuning of Large Language Models},
  author={Lu, Keming and Yuan, Hongyi and Yuan, Zheng and Lin, Runji and Lin, Junyang and Tan, Chuanqi and Zhou, Chang and Zhou, Jingren},
  booktitle={{ICLR}},
  publisher    = {OpenReview.net},
  year={2024}
}


@article{polylm,
  title={{PolyLM}: An open source polyglot large language model},
  author={Wei, Xiangpeng and Wei, Haoran and Lin, Huan and Li, Tianhao and Zhang, Pei and Ren, Xingzhang and Li, Mei and Wan, Yu and Cao, Zhiwei and Xie, Binbin and others},
  journal={CoRR},
  volume={abs/2307.06018},
  year={2023}
}

@article{refineweb,
  title={The {RefinedWeb} dataset for {Falcon} {LLM}: outperforming curated corpora with web data, and web data only},
  author={Penedo, Guilherme and Malartic, Quentin and Hesslow, Daniel and Cojocaru, Ruxandra and Cappelli, Alessandro and Alobeidli, Hamza and Pannier, Baptiste and Almazrouei, Ebtesam and Launay, Julien},
  journal={CoRR},
  volume={abs/2306.01116},
  year={2023}
}

@misc{bard,
  title = {An important next step on our {AI} journey},
  author = {Google},
  url = {https://blog.google/technology/ai/bard-google-ai-search-updates/},
  year={2023}
}

@misc{opencompass,
  title = {{OpenCompass}: A universal evaluation platform for foundation models},
  author = {{OpenCompass Contributors}},
  url = {https://github.com/open-compass/opencompass},
  year={2023}
}

@misc{chatml,
  title = {{ChatML}},
  author = {{OpenAI}},
  url = {https://github.com/openai/openai-python/blob/e389823ba013a24b4c32ce38fa0bd87e6bccae94/chatml.md},
  year = {2022}
}

@misc{code_interpreter,
  title = {{ChatGPT plugins}},
  author = {{OpenAI}},
  url = {https://openai.com/blog/chatgpt-plugins},
  year = {2023}
}

@article{xlmr,
  title={Unsupervised cross-lingual representation learning at scale},
  author={Conneau, Alexis and Khandelwal, Kartikay and Goyal, Naman and Chaudhary, Vishrav and Wenzek, Guillaume and Guzm{\'a}n, Francisco and Grave, Edouard and Ott, Myle and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={CoRR},
  volume={abs/1911.02116},
  year={2019}
}

@inproceedings{singla2024dynamic,
  author       = {Somanshu Singla and
                  Zhen Wang and
                  Tianyang Liu and
                  Abdullah Ashfaq and
                  Zhiting Hu and
                  Eric P. Xing},
  title        = {Dynamic Rewarding with Prompt Optimization Enables Tuning-free Self-Alignment
                  of Language Models},
  booktitle    = {{EMNLP}},
  pages        = {21889--21909},
  publisher    = {Association for Computational Linguistics},
  year         = {2024}
}

@misc{StableBeluga2,
  title = {{StableBeluga2}},
  author = {{Stability AI}},
  url = {https://huggingface.co/stabilityai/StableBeluga2},
  year = {2023}
}


@misc{qwen-tool-eval,
  title = {Evaluation Benchmark for Tool Usage through {ReAct} Prompting},
  author = {{Qwen Team, Alibaba Group}},
  url = {https:
//github.com/QwenLM/Qwen-7B/tree/main/eval},
  year = {2023}
}

@article{code_llama,
  title={Code {Llama}: Open foundation models for code},
  author={Rozi{\`e}re, Baptiste and Gehring, Jonas and Gloeckle, Fabian and Sootla, Sten and Gat, Itai and Tan, Xiaoqing Ellen and Adi, Yossi and Liu, Jingyu and Remez, Tal and Rapin, J{\'e}r{\'e}my and others},
  journal={CoRR},
  volume={abs/2308.12950},
  year={2023}
}

@misc{qwen-code-interpreter-eval,
  title = {Evaluation Benchmark for Code Intepreter},
  author = {{Qwen Team}},
  url = { https:
//github.com/QwenLM/Qwen-Agent/tree/main/benchmark},
  year = {2023}
}


@misc{claude,
  title = {Introducing {Claude}},
  author = {Anthropic},
  institution = {Anthropic},
  url = {https://www.anthropic.com/index/introducing-claude},
  year={2023}
}


@techreport{claude2,
  title = {Claude 2},
  author = {Anthropic},
  institution = {Anthropic},
  url = {https://www-files.anthropic.com/production/images/Model-Card-Claude-2.pdf},
  year={2023}
}

@misc{langchain,
    title = {{LangChain}: Building applications with {LLMs} through composability},
    author = {{LangChain, Inc.}},
    url = {https://python.langchain.com/},
    year = {2023}
}

@article{rope,
  author       = {Jianlin Su and
                  Murtadha H. M. Ahmed and
                  Yu Lu and
                  Shengfeng Pan and
                  Wen Bo and
                  Yunfeng Liu},
  title        = {RoFormer: Enhanced {Transformer} with Rotary Position Embedding},
  journal      = {Neurocomputing},
  volume       = {568},
  pages        = {127063},
  year         = {2024}
}

@misc{qwen1.5,
    title = {Introducing {Qwen1.5}},
    url = {https://qwenlm.github.io/blog/qwen1.5/},
    author = {{Qwen Team}},
    year = {2024}
}

@inproceedings{bostrom2020byte,
    title = "Byte Pair Encoding is Suboptimal for Language Model Pretraining",
    author = "Bostrom, Kaj  and
      Durrett, Greg",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.findings-emnlp.414",
    doi = "10.18653/v1/2020.findings-emnlp.414",
    pages = "4617--4624",
    abstract = "The success of pretrained transformer language models (LMs) in natural language processing has led to a wide range of pretraining setups. In particular, these models employ a variety of subword tokenization methods, most notably byte-pair encoding (BPE) (Sennrich et al., 2016; Gage, 1994), the WordPiece method (Schuster and Nakajima, 2012), and unigram language modeling (Kudo, 2018), to segment text. However, to the best of our knowledge, the literature does not contain a direct evaluation of the impact of tokenization on language model pretraining. We analyze differences between BPE and unigram LM tokenization, finding that the latter method recovers subword units that align more closely with morphology and avoids problems stemming from BPE{'}s greedy construction procedure. We then compare the fine-tuned task performance of identical transformer masked language models pretrained with these tokenizations. Across downstream tasks and two languages (English and Japanese), we find that the unigram LM tokenization method matches or outperforms BPE. We hope that developers of future pretrained LMs will consider adopting the unigram LM method over the more prevalent BPE.",
}

@inproceedings{gpt3,
  author       = {Tom B. Brown and
                  Benjamin Mann and
                  Nick Ryder and
                  Melanie Subbiah and
                  Jared Kaplan and
                  Prafulla Dhariwal and
                  Arvind Neelakantan and
                  Pranav Shyam and
                  Girish Sastry and
                  Amanda Askell and
                  Sandhini Agarwal and
                  Ariel Herbert{-}Voss and
                  Gretchen Krueger and
                  Tom Henighan and
                  Rewon Child and
                  Aditya Ramesh and
                  Daniel M. Ziegler and
                  Jeffrey Wu and
                  Clemens Winter and
                  Christopher Hesse and
                  Mark Chen and
                  Eric Sigler and
                  Mateusz Litwin and
                  Scott Gray and
                  Benjamin Chess and
                  Jack Clark and
                  Christopher Berner and
                  Sam McCandlish and
                  Alec Radford and
                  Ilya Sutskever and
                  Dario Amodei},
  title        = {Language Models are Few-Shot Learners},
  booktitle    = {NeurIPS},
  year         = {2020}
}

@article{llama,
  title={{LLaMA}: Open and efficient foundation language models},
  author       = {Hugo Touvron and
                  Thibaut Lavril and
                  Gautier Izacard and
                  Xavier Martinet and
                  Marie{-}Anne Lachaux and
                  Timoth{\'{e}}e Lacroix and
                  Baptiste Rozi{\`{e}}re and
                  Naman Goyal and
                  Eric Hambro and
                  Faisal Azhar and
                  Aur{\'{e}}lien Rodriguez and
                  Armand Joulin and
                  Edouard Grave and
                  Guillaume Lample},
  journal      = {CoRR},
  volume       = {abs/2302.13971},
  year         = {2023}
}

@article{llama2,
  author       = {Hugo Touvron and
                  Louis Martin and
                  Kevin Stone and
                  Peter Albert and
                  Amjad Almahairi and
                  Yasmine Babaei and
                  Nikolay Bashlykov and
                  Soumya Batra and
                  Prajjwal Bhargava and
                  Shruti Bhosale and
                  Dan Bikel and
                  Lukas Blecher and
                  Cristian Canton{-}Ferrer and
                  Moya Chen and
                  Guillem Cucurull and
                  David Esiobu and
                  Jude Fernandes and
                  Jeremy Fu and
                  Wenyin Fu and
                  Brian Fuller and
                  Cynthia Gao and
                  Vedanuj Goswami and
                  Naman Goyal and
                  Anthony Hartshorn and
                  Saghar Hosseini and
                  Rui Hou and
                  Hakan Inan and
                  Marcin Kardas and
                  Viktor Kerkez and
                  Madian Khabsa and
                  Isabel Kloumann and
                  Artem Korenev and
                  Punit Singh Koura and
                  Marie{-}Anne Lachaux and
                  Thibaut Lavril and
                  Jenya Lee and
                  Diana Liskovich and
                  Yinghai Lu and
                  Yuning Mao and
                  Xavier Martinet and
                  Todor Mihaylov and
                  Pushkar Mishra and
                  Igor Molybog and
                  Yixin Nie and
                  Andrew Poulton and
                  Jeremy Reizenstein and
                  Rashi Rungta and
                  Kalyan Saladi and
                  Alan Schelten and
                  Ruan Silva and
                  Eric Michael Smith and
                  Ranjan Subramanian and
                  Xiaoqing Ellen Tan and
                  Binh Tang and
                  Ross Taylor and
                  Adina Williams and
                  Jian Xiang Kuan and
                  Puxin Xu and
                  Zheng Yan and
                  Iliyan Zarov and
                  Yuchen Zhang and
                  Angela Fan and
                  Melanie Kambadur and
                  Sharan Narang and
                  Aur{\'{e}}lien Rodriguez and
                  Robert Stojnic and
                  Sergey Edunov and
                  Thomas Scialom},
  title        = {Llama 2: Open Foundation and Fine-Tuned Chat Models},
  journal      = {CoRR},
  volume       = {abs/2307.09288},
  year         = {2023}
}

@article{layer_norm,
  author       = {Lei Jimmy Ba and
                  Jamie Ryan Kiros and
                  Geoffrey E. Hinton},
  title        = {Layer Normalization},
  journal      = {CoRR},
  volume       = {abs/1607.06450},
  year         = {2016},
  url          = {http://arxiv.org/abs/1607.06450},
  eprinttype    = {arXiv},
  eprint       = {1607.06450},
  timestamp    = {Tue, 23 Jul 2019 17:33:23 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/BaKH16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{rmsnorm,
  author       = {Zixuan Jiang and
                  Jiaqi Gu and
                  Hanqing Zhu and
                  David Z. Pan},
  title        = {{Pre-RMSNorm} and {Pre-CRMSNorm} {Transformers}: Equivalent and Efficient
                  Pre-{LN} {Transformers}},
  journal      = {CoRR},
  volume       = {abs/2305.14858},
  year         = {2023}
}

@article{geglu,
  author       = {Noam Shazeer},
  title        = {{GLU} Variants Improve Transformer},
  journal      = {CoRR},
  volume       = {abs/2002.05202},
  year         = {2020},
  url          = {https://arxiv.org/abs/2002.05202},
  eprinttype    = {arXiv},
  eprint       = {2002.05202},
  timestamp    = {Fri, 14 Feb 2020 12:07:41 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2002-05202.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{gelu,
  author       = {Dan Hendrycks and
                  Kevin Gimpel},
  title        = {Bridging Nonlinearities and Stochastic Regularizers with {Gaussian}
                  Error Linear Units},
  journal      = {CoRR},
  volume       = {abs/1606.08415},
  year         = {2016},
  url          = {http://arxiv.org/abs/1606.08415},
  eprinttype    = {arXiv},
  eprint       = {1606.08415},
  timestamp    = {Mon, 13 Aug 2018 16:46:20 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/HendrycksG16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{glu,
  author       = {Yann N. Dauphin and
                  Angela Fan and
                  Michael Auli and
                  David Grangier},
  title        = {Language Modeling with Gated Convolutional Networks},
  booktitle    = {{ICML}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {70},
  pages        = {933--941},
  publisher    = {{PMLR}},
  year         = {2017}
}

@article{noamglu,
  title={{GLU} variants improve transformer},
  author={Shazeer, Noam},
  journal={CoRR},
  volume={abs/2002.05202},
  year={2020}
}

@article{swish,
  title={Searching for activation functions},
  author={Ramachandran, Prajit and Zoph, Barret and Le, Quoc V},
  journal={CoRR},
  volume={abs/1710.05941},
  year={2017}
}

@article{gpt4,
  title={{GPT4} technical report},
  author={{OpenAI}},
  journal={CoRR},
  volume={abs/2303.08774},
  year={2023}
}

@misc{tiktoken,
   title = {{tiktoken}: A fast {BPE} tokeniser for use with {OpenAI}'s models},
   author = {Shantanu Jain},
   institution = {OpenAI},
   year = {2022},
   url = {https://github.com/openai/tiktoken/}
}

@inproceedings{flashattn,
  author       = {Tri Dao and
                  Daniel Y. Fu and
                  Stefano Ermon and
                  Atri Rudra and
                  Christopher R{\'{e}}},
  title        = {{FlashAttention}: Fast and Memory-Efficient Exact Attention with IO-Awareness},
  booktitle    = {NeurIPS},
  year         = {2022},
  url          = {http://papers.nips.cc/paper\_files/paper/2022/hash/67d57c32e20fd0a7a302cb81d36e40d5-Abstract-Conference.html},
  timestamp    = {Thu, 11 May 2023 17:08:21 +0200},
  biburl       = {https://dblp.org/rec/conf/nips/DaoFERR22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{transformer,
  author       = {Ashish Vaswani and
                  Noam Shazeer and
                  Niki Parmar and
                  Jakob Uszkoreit and
                  Llion Jones and
                  Aidan N. Gomez and
                  Lukasz Kaiser and
                  Illia Polosukhin},
  title        = {Attention is All you Need},
  booktitle    = {{NIPS}},
  pages        = {5998--6008},
  year         = {2017}
}

@article{roberta,
  title={{RoBERTa}: A robustly optimized {BERT} pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={CoRR},
  volume={abs/1907.11692},
  year={2019}
}



@inproceedings{flan,
  author       = {Jason Wei and
                  Maarten Bosma and
                  Vincent Y. Zhao and
                  Kelvin Guu and
                  Adams Wei Yu and
                  Brian Lester and
                  Nan Du and
                  Andrew M. Dai and
                  Quoc V. Le},
  title        = {Finetuned Language Models are Zero-Shot Learners},
  booktitle    = {The Tenth International Conference on Learning Representations, {ICLR}
                  2022, Virtual Event, April 25-29, 2022},
  publisher    = {OpenReview.net},
  year         = {2022},
  url          = {https://openreview.net/forum?id=gEZrGCozdqR},
  timestamp    = {Wed, 16 Aug 2023 16:10:28 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/WeiBZGYLDDL22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{flanv2,
  title={Scaling instruction-finetuned language models},
  author={Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Eric and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and others},
  journal={CoRR},
  volume={abs/2210.11416},
  year={2022}
}

@article{flan-collection,
  title={The {Flan} collection: Designing data and methods for effective instruction tuning},
  author={Longpre, Shayne and Hou, Le and Vu, Tu and Webson, Albert and Chung, Hyung Won and Tay, Yi and Zhou, Denny and Le, Quoc V and Zoph, Barret and Wei, Jason and others},
  journal={CoRR},
  volume={abs/2301.13688},
  year={2023}
}

@misc{codeqwen1.5,
    title = {Code with CodeQwen1.5},
    url = {https://qwenlm.github.io/blog/codeqwen1.5/},
    author = {{Qwen Team}},
    month = {April},
    year = {2024}
}

@article{cai,
  title={Constitutional {AI}: Harmlessness from {AI} feedback},
  author={Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  journal={CoRR},
  volume={abs/2212.08073},
  year={2022}
}

@inproceedings{rlhf,
  author       = {Paul F. Christiano and
                  Jan Leike and
                  Tom B. Brown and
                  Miljan Martic and
                  Shane Legg and
                  Dario Amodei},
  editor       = {Isabelle Guyon and
                  Ulrike von Luxburg and
                  Samy Bengio and
                  Hanna M. Wallach and
                  Rob Fergus and
                  S. V. N. Vishwanathan and
                  Roman Garnett},
  title        = {Deep Reinforcement Learning from Human Preferences},
  booktitle    = {Advances in Neural Information Processing Systems 30: Annual Conference
                  on Neural Information Processing Systems 2017, December 4-9, 2017,
                  Long Beach, CA, {USA}},
  pages        = {4299--4307},
  year         = {2017},
  url          = {https://proceedings.neurips.cc/paper/2017/hash/d5e2c0adad503c91f91df240d0cd4e49-Abstract.html},
  timestamp    = {Thu, 21 Jan 2021 15:15:21 +0100},
  biburl       = {https://dblp.org/rec/conf/nips/ChristianoLBMLA17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{red-teaming,
  title={Red teaming language models to reduce harms: Methods, scaling behaviors, and lessons learned},
  author={Ganguli, Deep and Lovitt, Liane and Kernion, Jackson and Askell, Amanda and Bai, Yuntao and Kadavath, Saurav and Mann, Ben and Perez, Ethan and Schiefer, Nicholas and Ndousse, Kamal and others},
  journal={CoRR},
  volume={abs/2209.07858},
  year={2022}
}

@misc{transformers-agents,
    title = {Transformers Agents},
    author = {{Hugging Face}},
    url = {https://huggingface.co/docs/transformers/transformers_agents}, 
    year = {2023}
}


@misc{qwen1.5moe,
    title = {{Qwen1.5-MoE}: Matching {7B} Model Performance with 1/3 Activated Parameters},
    url = {https://qwenlm.github.io/blog/qwen-moe/},
    author = {{Qwen Team}},
    year = {2024}
}

@article{thestack,
  author       = {Denis Kocetkov and
                  Raymond Li and
                  Loubna Ben Allal and
                  Jia Li and
                  Chenghao Mou and
                  Carlos Mu{\~{n}}oz Ferrandis and
                  Yacine Jernite and
                  Margaret Mitchell and
                  Sean Hughes and
                  Thomas Wolf and
                  Dzmitry Bahdanau and
                  Leandro von Werra and
                  Harm de Vries},
  title        = {The Stack: 3 {TB} of permissively licensed source code},
  journal      = {CoRR},
  volume       = {abs/2211.15533},
  year         = {2022},
  url          = {https://doi.org/10.48550/arXiv.2211.15533},
  doi          = {10.48550/arXiv.2211.15533},
  eprinttype    = {arXiv},
  eprint       = {2211.15533},
  timestamp    = {Tue, 29 Nov 2022 17:41:18 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2211-15533.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{codeparrot-github-clean,
title = {{GitHub} Code Dataset Cleaned},
author = {{CodeParrot}},
url = {https://huggingface.co/datasets/codeparrot/github-code-clean},
year = {2022}
}

@article{starcoder,
  author       = {Raymond Li and
                  Loubna Ben Allal and
                  Yangtian Zi and
                  Niklas Muennighoff and
                  Denis Kocetkov and
                  Chenghao Mou and
                  Marc Marone and
                  Christopher Akiki and
                  Jia Li and
                  Jenny Chim and
                  Qian Liu and
                  Evgenii Zheltonozhskii and
                  Terry Yue Zhuo and
                  Thomas Wang and
                  Olivier Dehaene and
                  Mishig Davaadorj and
                  Joel Lamy{-}Poirier and
                  Jo{\~{a}}o Monteiro and
                  Oleh Shliazhko and
                  Nicolas Gontier and
                  Nicholas Meade and
                  Armel Zebaze and
                  Ming{-}Ho Yee and
                  Logesh Kumar Umapathi and
                  Jian Zhu and
                  Benjamin Lipkin and
                  Muhtasham Oblokulov and
                  Zhiruo Wang and
                  Rudra Murthy V and
                  Jason Stillerman and
                  Siva Sankalp Patel and
                  Dmitry Abulkhanov and
                  Marco Zocca and
                  Manan Dey and
                  Zhihan Zhang and
                  Nour Moustafa{-}Fahmy and
                  Urvashi Bhattacharyya and
                  Wenhao Yu and
                  Swayam Singh and
                  Sasha Luccioni and
                  Paulo Villegas and
                  Maxim Kunakov and
                  Fedor Zhdanov and
                  Manuel Romero and
                  Tony Lee and
                  Nadav Timor and
                  Jennifer Ding and
                  Claire Schlesinger and
                  Hailey Schoelkopf and
                  Jan Ebert and
                  Tri Dao and
                  Mayank Mishra and
                  Alex Gu and
                  Jennifer Robinson and
                  Carolyn Jane Anderson and
                  Brendan Dolan{-}Gavitt and
                  Danish Contractor and
                  Siva Reddy and
                  Daniel Fried and
                  Dzmitry Bahdanau and
                  Yacine Jernite and
                  Carlos Mu{\~{n}}oz Ferrandis and
                  Sean Hughes and
                  Thomas Wolf and
                  Arjun Guha and
                  Leandro von Werra and
                  Harm de Vries},
  title        = {{StarCoder}: May the source be with you!},
  journal      = {CoRR},
  volume       = {abs/2305.06161},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2305.06161},
  doi          = {10.48550/arXiv.2305.06161},
  eprinttype    = {arXiv},
  eprint       = {2305.06161},
  timestamp    = {Fri, 23 Jun 2023 22:30:55 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2305-06161.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{generalist,
  author       = {Scott E. Reed and
                  Konrad Zolna and
                  Emilio Parisotto and
                  Sergio G{\'{o}}mez Colmenarejo and
                  Alexander Novikov and
                  Gabriel Barth{-}Maron and
                  Mai Gimenez and
                  Yury Sulsky and
                  Jackie Kay and
                  Jost Tobias Springenberg and
                  Tom Eccles and
                  Jake Bruce and
                  Ali Razavi and
                  Ashley Edwards and
                  Nicolas Heess and
                  Yutian Chen and
                  Raia Hadsell and
                  Oriol Vinyals and
                  Mahyar Bordbar and
                  Nando de Freitas},
  title        = {A Generalist Agent},
  journal      = {Trans. Mach. Learn. Res.},
  volume       = {2022},
  year         = {2022},
  url          = {https://openreview.net/forum?id=1ikK0kHjvj},
  timestamp    = {Fri, 19 May 2023 11:20:41 +0200},
  biburl       = {https://dblp.org/rec/journals/tmlr/ReedZPCNBGSKSEBREHCHVBF22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{gemma2,
  title={Gemma 2: Improving open language models at a practical size},
  author={{Gemma Team} and Riviere, Morgane and Pathak, Shreya and Sessa, Pier Giuseppe and Hardin, Cassidy and Bhupatiraju, Surya and Hussenot, L{\'e}onard and Mesnard, Thomas and Shahriari, Bobak and Ram{\'e}, Alexandre and others},
  journal={CoRR},
  volume={abs/2408.00118},
  year={2024}
}

@article{mmluredux,
  title={Are We Done with MMLU?},
  author={Gema, Aryo Pradipta and Leang, Joshua Ong Jun and Hong, Giwon and Devoto, Alessio and Mancino, Alberto Carlo Maria and Saxena, Rohit and He, Xuanli and Zhao, Yu and Du, Xiaotang and Madani, Mohammad Reza Ghasemi and others},
  journal={CoRR},
  volume={abs/2406.04127},
  year={2024}
}

@misc{chatgpt,
    title = {Introducing {ChatGPT}} ,
    author = {{OpenAI}},
    url = {https://openai.com/index/chatgpt/},
    year = {2022}
}

@inproceedings{instructgpt,
  author       = {Long Ouyang and
                  Jeffrey Wu and
                  Xu Jiang and
                  Diogo Almeida and
                  Carroll L. Wainwright and
                  Pamela Mishkin and
                  Chong Zhang and
                  Sandhini Agarwal and
                  Katarina Slama and
                  Alex Ray and
                  John Schulman and
                  Jacob Hilton and
                  Fraser Kelton and
                  Luke Miller and
                  Maddie Simens and
                  Amanda Askell and
                  Peter Welinder and
                  Paul F. Christiano and
                  Jan Leike and
                  Ryan Lowe},
  title        = {Training language models to follow instructions with human feedback},
  booktitle    = {NeurIPS},
  year         = {2022},
  timestamp    = {Thu, 11 May 2023 17:08:21 +0200},
  biburl       = {https://dblp.org/rec/conf/nips/Ouyang0JAWMZASR22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{o1,
    title={Learning to Reason with {LLMs}},
    author={{OpenAI}},
    url={https://openai.com/index/learning-to-reason-with-llms/},
    year={2024}
}

@inproceedings{wolfe2024laboratory,
  author       = {Robert Wolfe and
                  Isaac Slaughter and
                  Bin Han and
                  Bingbing Wen and
                  Yiwei Yang and
                  Lucas Rosenblatt and
                  Bernease Herman and
                  Eva Maxfield Brown and
                  Zening Qu and
                  Nic Weber and
                  Bill Howe},
  title        = {Laboratory-Scale {AI:} Open-Weight Models are Competitive with {ChatGPT}
                  Even in Low-Resource Settings},
  booktitle    = {FAccT},
  pages        = {1199--1210},
  publisher    = {{ACM}},
  year         = {2024}
}

@inproceedings{kapoor2024societal,
  author       = {Sayash Kapoor and
                  Rishi Bommasani and
                  Kevin Klyman and
                  Shayne Longpre and
                  Ashwin Ramaswami and
                  Peter Cihon and
                  Aspen K. Hopkins and
                  Kevin Bankston and
                  Stella Biderman and
                  Miranda Bogen and
                  Rumman Chowdhury and
                  Alex Engler and
                  Peter Henderson and
                  Yacine Jernite and
                  Seth Lazar and
                  Stefano Maffulli and
                  Alondra Nelson and
                  Joelle Pineau and
                  Aviya Skowron and
                  Dawn Song and
                  Victor Storchan and
                  Daniel Zhang and
                  Daniel E. Ho and
                  Percy Liang and
                  Arvind Narayanan},
  title        = {Position: On the Societal Impact of Open Foundation Models},
  booktitle    = {{ICML}},
  publisher    = {OpenReview.net},
  year         = {2024}
}

@article{qwen2.5coder,
  title={{Qwen2.5-Coder} technical report},
  author={Hui, Binyuan and Yang, Jian and Cui, Zeyu and Yang, Jiaxi and Liu, Dayiheng and Zhang, Lei and Liu, Tianyu and Zhang, Jiajun and Yu, Bowen and Lu, Keming and others},
  journal={CoRR},
  volume={abs/2409.12186},
  year={2024}
}


@misc{qwen2math,
  title={{Introducing Qwen2-Math}},
  author={{Qwen Team}},
  year={2024},
  url={https://qwenlm.github.io/blog/qwen2-math/}
}

@article{qwen2.5math,
  title={{Qwen2.5-Math} technical report: Toward mathematical expert model via self-improvement},
  author={Yang, An and Zhang, Beichen and Hui, Binyuan and Gao, Bofei and Yu, Bowen and Li, Chengpeng and Liu, Dayiheng and Tu, Jianhong and Zhou, Jingren and Lin, Junyang and others},
  journal={CoRR},
  volume={abs/2409.12122},
  year={2024}
}

@article{kaplanscaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={CoRR},
  volume={abs/2001.08361},
  year={2020}
}

@article{chinchilla,
  title={Training compute-optimal large language models},
  author={Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and others},
  journal={CoRR},
  volume={abs/2203.15556},
  year={2022}
}

@article{scaling_rush,
  title={Scaling Data-Constrained Language Models},
  author={Muennighoff, Niklas and Rush, Alexander M and Barak, Boaz and Scao, Teven Le and Piktus, Aleksandra and Tazi, Nouamane and Pyysalo, Sampo and Wolf, Thomas and Raffel, Colin},
  journal={CoRR},
  volume={abs/2305.16264},
  year={2023}
}


@inproceedings{mmlu,
  author       = {Dan Hendrycks and
                  Collin Burns and
                  Steven Basart and
                  Andy Zou and
                  Mantas Mazeika and
                  Dawn Song and
                  Jacob Steinhardt},
  title        = {Measuring Massive Multitask Language Understanding},
  booktitle    = {{ICLR}},
  publisher    = {OpenReview.net},
  year         = {2021}
}

@inproceedings{bbh,
  author       = {Mirac Suzgun and
                  Nathan Scales and
                  Nathanael Sch{\"{a}}rli and
                  Sebastian Gehrmann and
                  Yi Tay and
                  Hyung Won Chung and
                  Aakanksha Chowdhery and
                  Quoc V. Le and
                  Ed H. Chi and
                  Denny Zhou and
                  Jason Wei},
  title        = {Challenging {BIG-Bench} Tasks and Whether Chain-of-Thought Can Solve
                  Them},
  booktitle    = {{ACL} (Findings)},
  pages        = {13003--13051},
  publisher    = {Association for Computational Linguistics},
  year         = {2023}
}

@article{mbpp,
  author       = {Jacob Austin and
                  Augustus Odena and
                  Maxwell I. Nye and
                  Maarten Bosma and
                  Henryk Michalewski and
                  David Dohan and
                  Ellen Jiang and
                  Carrie J. Cai and
                  Michael Terry and
                  Quoc V. Le and
                  Charles Sutton},
  title        = {Program Synthesis with Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2108.07732},
  year         = {2021}
}

@article{cmmlu,
  author       = {Haonan Li and
                  Yixuan Zhang and
                  Fajri Koto and
                  Yifei Yang and
                  Hai Zhao and
                  Yeyun Gong and
                  Nan Duan and
                  Timothy Baldwin},
  title        = {{CMMLU}: Measuring massive multitask language understanding in {Chinese}},
  journal      = {CoRR},
  volume       = {abs/2306.09212},
  year         = {2023}
}

@inproceedings{ceval,
  author       = {Yuzhen Huang and
                  Yuzhuo Bai and
                  Zhihao Zhu and
                  Junlei Zhang and
                  Jinghan Zhang and
                  Tangjun Su and
                  Junteng Liu and
                  Chuancheng Lv and
                  Yikai Zhang and
                  Jiayi Lei and
                  Yao Fu and
                  Maosong Sun and
                  Junxian He},
  title        = {{C-Eval}: A Multi-Level Multi-Discipline Chinese Evaluation Suite
                  for Foundation Models},
  booktitle    = {NeurIPS},
  year         = {2023}
}

@article{gsm8k,
  author       = {Karl Cobbe and
                  Vineet Kosaraju and
                  Mohammad Bavarian and
                  Mark Chen and
                  Heewoo Jun and
                  Lukasz Kaiser and
                  Matthias Plappert and
                  Jerry Tworek and
                  Jacob Hilton and
                  Reiichiro Nakano and
                  Christopher Hesse and
                  John Schulman},
  title        = {Training Verifiers to Solve Math Word Problems},
  journal      = {CoRR},
  volume       = {abs/2110.14168},
  year         = {2021}
}


@article{pile,
  title={The {Pile}: An {800GB} dataset of diverse text for language modeling},
  author={Gao, Leo and Biderman, Stella and Black, Sid and Golding, Laurence and Hoppe, Travis and Foster, Charles and Phang, Jason and He, Horace and Thite, Anish and Nabeshima, Noa and others},
  journal={CoRR},
  volume={abs/2101.00027},
  year={2020}
}



@article{t5,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={The Journal of Machine Learning Research},
  volume={21},
  number={1},
  pages={5485--5551},
  year={2020},
  publisher={JMLRORG}
}

@article{llava,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={CoRR},
  volume={abs/2304.08485},
  year={2023}
}

@article{instructblip,
  title={{InstructBLIP}: Towards General-purpose Vision-Language Models with Instruction Tuning},
  author={Dai, Wenliang and Li, Junnan and Li, Dongxu and Meng, Anthony and  Tiong, Huat and Zhao, Junqi and Wang, Weisheng and Li, Boyang and Fung, Pascale and Hoi, Steven},
  journal={CoRR},
  volume={abs/2305.06500},
  year={2023}
}

@article{kosmos2,
  title={Kosmos-2: Grounding Multimodal Large Language Models to the World},
  author={Peng, Zhiliang and Wang, Wenhui and Dong, Li and Hao, Yaru and Huang, Shaohan and Ma, Shuming and Wei, Furu},
  journal={CoRR},
  volume={abs/2306.14824},
  year={2023}
}

@article{toolformer,
  title={Toolformer: Language models can teach themselves to use tools},
  author={Schick, Timo and Dwivedi-Yu, Jane and Dess{\`\i}, Roberto and Raileanu, Roberta and Lomeli, Maria and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  journal={CoRR},
  volume={abs/2302.04761},
  year={2023}
}

@article{megatron,
  title={{Megatron-LM}: Training multi-billion parameter language models using model parallelism},
  author={Shoeybi, Mohammad and Patwary, Mostofa and Puri, Raul and LeGresley, Patrick and Casper, Jared and Catanzaro, Bryan},
  journal={CoRR},
  volume={abs/1909.08053},
  year={2019}
}

@article{bloom,
  title={{BLOOM}: A {176B}-parameter open-access multilingual language model},
  author={Scao, Teven Le and Fan, Angela and Akiki, Christopher and Pavlick, Ellie and Ili{\'c}, Suzana and Hesslow, Daniel and Castagn{\'e}, Roman and Luccioni, Alexandra Sasha and Yvon, Fran{\c{c}}ois and Gall{\'e}, Matthias and others},
  journal={CoRR},
  volume={abs/2211.05100},
  year={2022}
}

@inproceedings{xwinograd,
  author       = {Niklas Muennighoff and
                  Thomas Wang and
                  Lintang Sutawika and
                  Adam Roberts and
                  Stella Biderman and
                  Teven Le Scao and
                  M. Saiful Bari and
                  Sheng Shen and
                  Zheng Xin Yong and
                  Hailey Schoelkopf and
                  Xiangru Tang and
                  Dragomir Radev and
                  Alham Fikri Aji and
                  Khalid Almubarak and
                  Samuel Albanie and
                  Zaid Alyafeai and
                  Albert Webson and
                  Edward Raff and
                  Colin Raffel},
  title        = {Crosslingual Generalization through Multitask Finetuning},
  booktitle    = {{ACL} {(1)}},
  pages        = {15991--16111},
  publisher    = {Association for Computational Linguistics},
  year         = {2023}
}

@article{opt,
  title={{OPT}: Open pre-trained transformer language models},
  author={Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and others},
  journal={CoRR},
  volume={abs/2205.01068},
  year={2022}
}

@article{glm-130b,
  title={{GLM-130B}: An open bilingual pre-trained model},
  author={Zeng, Aohan and Liu, Xiao and Du, Zhengxiao and Wang, Zihan and Lai, Hanyu and Ding, Ming and Yang, Zhuoyi and Xu, Yifan and Zheng, Wendi and Xia, Xiao and others},
  journal={CoRR},
  volume={abs/2210.02414},
  year={2022}
}

@article{glm,
  title={{GLM}: General language model pretraining with autoregressive blank infilling},
  author={Du, Zhengxiao and Qian, Yujie and Liu, Xiao and Ding, Ming and Qiu, Jiezhong and Yang, Zhilin and Tang, Jie},
  journal={CoRR},
  volume={abs/2103.10360},
  year={2021}
}

@inproceedings{glam,
  title={{GLaM}: Efficient scaling of language models with mixture-of-experts},
  author={Du, Nan and Huang, Yanping and Dai, Andrew M and Tong, Simon and Lepikhin, Dmitry and Xu, Yuanzhong and Krikun, Maxim and Zhou, Yanqi and Yu, Adams Wei and Firat, Orhan and others},
  booktitle={International Conference on Machine Learning},
  pages={5547--5569},
  year={2022},
  organization={PMLR}
}

@article{gshard,
  title={{GShard}: Scaling giant models with conditional computation and automatic sharding},
  author={Lepikhin, Dmitry and Lee, HyoukJoong and Xu, Yuanzhong and Chen, Dehao and Firat, Orhan and Huang, Yanping and Krikun, Maxim and Shazeer, Noam and Chen, Zhifeng},
  journal={CoRR},
  volume={abs/2006.16668},
  year={2020}
}

@article{switch_transformer,
  author       = {William Fedus and
                  Barret Zoph and
                  Noam Shazeer},
  title        = {Switch Transformers: Scaling to Trillion Parameter Models with Simple
                  and Efficient Sparsity},
  journal      = {J. Mach. Learn. Res.},
  volume       = {23},
  pages        = {120:1--120:39},
  year         = {2022}
}

@article{stmoe,
  title={{ST-MoE}: Designing stable and transferable sparse expert models},
  author={Zoph, Barret and Bello, Irwan and Kumar, Sameer and Du, Nan and Huang, Yanping and Dean, Jeff and Shazeer, Noam and Fedus, William},
  journal={CoRR},
   volume={abs/2202.08906},
  year={2022}
}

@article{gpt-neo,
  title={{GPT-NeoX-20B}: An open-source autoregressive language model},
  author={Black, Sid and Biderman, Stella and Hallahan, Eric and Anthony, Quentin and Gao, Leo and Golding, Laurence and He, Horace and Leahy, Connor and McDonell, Kyle and Phang, Jason and others},
  journal={CoRR},
  volume={abs/2204.06745},
  year={2022}
}

@article{gopher,
  title={Scaling language models: Methods, analysis \& insights from training gopher},
  author={Rae, Jack W and Borgeaud, Sebastian and Cai, Trevor and Millican, Katie and Hoffmann, Jordan and Song, Francis and Aslanides, John and Henderson, Sarah and Ring, Roman and Young, Susannah and others},
  journal={CoRR},
  volume={abs/2112.11446},
  year={2021}
}

@article{foundation_models,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={CoRR},
  volume={abs/2108.07258},
  year={2021}
}

@misc{mpt,
    title={{MPT-30B}: Raising the bar for open-source foundation models},
    author={{Mosaic ML}},
    url={https://www.mosaicml.com/blog/mpt-30b},
    year={2023},
}

@article{falcon,
  author       = {Ebtesam Almazrouei and
                  Hamza Alobeidli and
                  Abdulaziz Alshamsi and
                  Alessandro Cappelli and
                  Ruxandra Cojocaru and
                  M{\'{e}}rouane Debbah and
                  {\'{E}}tienne Goffinet and
                  Daniel Hesslow and
                  Julien Launay and
                  Quentin Malartic and
                  Daniele Mazzotta and
                  Badreddine Noune and
                  Baptiste Pannier and
                  Guilherme Penedo},
  title        = {The {Falcon} Series of Open Language Models},
  journal      = {CoRR},
  volume       = {abs/2311.16867},
  year         = {2023}
}

@article{t0,
  title={Multitask prompted training enables zero-shot task generalization},
  author={Sanh, Victor and Webson, Albert and Raffel, Colin and Bach, Stephen H and Sutawika, Lintang and Alyafeai, Zaid and Chaffin, Antoine and Stiegler, Arnaud and Scao, Teven Le and Raja, Arun and others},
  journal={CoRR},
  volume={abs/2110.08207},
  year={2021}
}



@article{mplug-owl,
  title={{mPLUG-Owl}: Modularization empowers large language models with multimodality},
  author={Ye, Qinghao and Xu, Haiyang and Xu, Guohai and Ye, Jiabo and Yan, Ming and Zhou, Yiyang and Wang, Junyang and Hu, Anwen and Shi, Pengcheng and Shi, Yaya and others},
  journal={CoRR},
  volume={abs/2304.14178},
  year={2023}
}

@techreport{baichuan2,
    author = {Aiyuan Yang and Bin Xiao and Bingning Wang and Borong Zhang and Chao Yin and Chenxu Lv and Da Pan and Dian Wang and Dong Yan and Fan Yang and Fei Deng and Feng Wang and Feng Liu and Guangwei Ai and Guosheng Dong and Haizhou Zhao and Hang Xu and Haoze Sun and Hongda Zhang and Hui Liu and Jiaming Ji and Jian Xie and Juntao Dai and Kun Fang and Lei Su and Liang Song and Lifeng Liu and Liyun Ru and Luyao Ma and Mang Wang and Mickel Liu and MingAn Lin and Nuolan Nie and Peidong Guo and Ruiyang Sun and Tao Zhang and Tianpeng Li and Tianyu Li and Wei Cheng and Weipeng Chen and Xiangrong Zeng and Xiaochuan Wang and Xiaoxi Chen and Xin Men and Xin Yu and Xuehai Pan and Yanjun Shen and Yiding Wang and Yiyu Li and Youxin Jiang and Yuchen Gao and Yupeng Zhang and Zenan Zhou and Zhiying Wu},
    title = {Baichuan 2: Open Large-scale Language Models},
    institution = {Baichuan Inc.},
    year = {2023},
    url = {https://cdn.baichuan-ai.com/paper/Baichuan2-technical-report.pdf}
}

@article{self_align,
  title={Principle-driven self-alignment of language models from scratch with minimal human supervision},
  author={Sun, Zhiqing and Shen, Yikang and Zhou, Qinhong and Zhang, Hongxin and Chen, Zhenfang and Cox, David and Yang, Yiming and Gan, Chuang},
  journal={CoRR},
  volume={abs/2305.03047},
  year={2023}
}

@article{wizardlm,
  title={{WizardLM}: Empowering large language models to follow complex instructions},
  author={Xu, Can and Sun, Qingfeng and Zheng, Kai and Geng, Xiubo and Zhao, Pu and Feng, Jiazhan and Tao, Chongyang and Jiang, Daxin},
  journal={CoRR},
  volume={abs/2304.12244},
  year={2023}
}

@article{expertprompting,
  title={{ExpertPrompting}: Instructing Large Language Models to be Distinguished Experts},
  author={Xu, Benfeng and Yang, An and Lin, Junyang and Wang, Quan and Zhou, Chang and Zhang, Yongdong and Mao, Zhendong},
  journal={CoRR},
  volume={abs/2305.14688},
  year={2023}
}

@article{ultrachat,
  title={Enhancing Chat Language Models by Scaling High-quality Instructional Conversations},
  author={Ding, Ning and Chen, Yulin and Xu, Bokai and Qin, Yujia and Zheng, Zhi and Hu, Shengding and Liu, Zhiyuan and Sun, Maosong and Zhou, Bowen},
  journal={CoRR},
  volume={abs/2305.14233},
  year={2023}
}

@article{baize,
  title={{BaiZe}: An open-source chat model with parameter-efficient tuning on self-chat data},
  author={Xu, Canwen and Guo, Daya and Duan, Nan and McAuley, Julian},
  journal={CoRR},
  volume={abs/2304.01196},
  year={2023}
}

@article{phoenix,
  title={Phoenix: Democratizing {ChatGPT} across languages},
  author={Chen, Zhihong and Jiang, Feng and Chen, Junying and Wang, Tiannan and Yu, Fei and Chen, Guiming and Zhang, Hongbo and Liang, Juhao and Zhang, Chen and Zhang, Zhiyi and others},
  journal={CoRR},
  volume={abs/2304.10453},
  year={2023}
}

@misc{dolly,
    author    = {Mike Conover and Matt Hayes and Ankit Mathur and Jianwei Xie and Jun Wan and Sam Shah and Ali Ghodsi and Patrick Wendell and Matei Zaharia and Reynold Xin},
    title     = {Free {Dolly}: Introducing the World's First Truly Open Instruction-Tuned {LLM}},
    year      = {2023},
    url       = {https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm},
    urldate   = {2023-06-30}
}

@article{orca,
  title={Orca: Progressive learning from complex explanation traces of {GPT-4}},
  author={Mukherjee, Subhabrata and Mitra, Arindam and Jawahar, Ganesh and Agarwal, Sahaj and Palangi, Hamid and Awadallah, Ahmed},
  journal={CoRR},
  volume={abs/2306.02707},
  year={2023}
}

@misc{moss,
  title={{MOSS}: Training Conversational Language Models from Synthetic Data}, 
  author={Tianxiang Sun and Xiaotian Zhang and Zhengfu He and Peng Li and Qinyuan Cheng and Hang Yan and Xiangyang Liu and Yunfan Shao and Qiong Tang and Xingjian Zhao and Ke Chen and Yining Zheng and Zhejian Zhou and Ruixiao Li and Jun Zhan and Yunhua Zhou and Linyang Li and Xiaogui Yang and Lingling Wu and Zhangyue Yin and Xuanjing Huang and Xipeng Qiu},
  year={2023}
}



@article{huggingface,
  title={{HuggingFace}'s transformers: State-of-the-art natural language processing},
  author={Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and others},
  journal={CoRR},
  volume={abs/1910.03771},
  year={2019}
}

@article{adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={CoRR},
  volume={abs/1412.6980},
  year={2014}
}

@article{adamw,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={CoRR},
  volume={abs/1711.05101},
  year={2017}
}

@inproceedings{ul2,
  title={{UL2}: Unifying language learning paradigms},
  author={Tay, Yi and Dehghani, Mostafa and Tran, Vinh Q and Garcia, Xavier and Wei, Jason and Wang, Xuezhi and Chung, Hyung Won and Bahri, Dara and Schuster, Tal and Zheng, Steven and others},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@misc{internlm,
    title={{InternLM}: A Multilingual Language Model with Progressively Enhanced Capabilities},
    author={{InternLM Team}},
    url = {https://github.com/InternLM/InternLM},
    year={2023}
}

@misc{baichuan7b,
    title={Baichuan-{7B}: A large-scale {7B} pretraining language model developed by {BaiChuan-Inc}},
    author={Baichuan Inc.},
    url = {https://github.com/baichuan-inc/Baichuan-7B},
    year={2023}
}

@misc{chatglm2,
    title={{ChatGLM2-6B}: An Open Bilingual Chat {LLM}},
    author={{ChatGLM2 Team}},
    url = {https://github.com/THUDM/ChatGLM2-6B},
    year={2023}
}

@misc{xverse,
    title={{XVERSE-13B}: A multilingual large language model developed by {XVERSE Technology Inc.}},
    author={XVERSE Technology Inc.},
    url = {https://github.com/xverse-ai/XVERSE-13B},
    year={2023}
}

@misc{baichuan13b,
    title={Baichuan-{13B}: A {13B} large language model developed by Baichuan Intelligent Technology},
    author={Baichuan Inc.},
    url = {https://github.com/baichuan-inc/Baichuan-13B},
    year={2023}
}

@article{upalm,
  title={Transcending scaling laws with 0.1\% extra compute},
  author={Tay, Yi and Wei, Jason and Chung, Hyung Won and Tran, Vinh Q and So, David R and Shakeri, Siamak and Garcia, Xavier and Zheng, Huaixiu Steven and Rao, Jinfeng and Chowdhery, Aakanksha and others},
  journal={CoRR},
  volume={abs/2210.11399},
  year={2022}
}

@techreport{gpt,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  institution={{OpenAI}}
}

@article{qwenvl,
  author       = {Jinze Bai and
                  Shuai Bai and
                  Shusheng Yang and
                  Shijie Wang and
                  Sinan Tan and
                  Peng Wang and
                  Junyang Lin and
                  Chang Zhou and
                  Jingren Zhou},
  title        = {{Qwen-VL}: A Frontier Large Vision-Language Model with Versatile Abilities},
  journal      = {CoRR},
  volume       = {abs/2308.12966},
  year         = {2023}
}

@article{ofasys,
  author       = {Jinze Bai and
                  Rui Men and
                  Hao Yang and
                  Xuancheng Ren and
                  Kai Dang and
                  Yichang Zhang and
                  Xiaohuan Zhou and
                  Peng Wang and
                  Sinan Tan and
                  An Yang andf
                  Zeyu Cui and
                  Yu Han and
                  Shuai Bai and
                  Wenbin Ge and
                  Jianxin Ma and
                  Junyang Lin and
                  Jingren Zhou and
                  Chang Zhou},
  title        = {{OFASys}: {A} Multi-Modal Multi-Task Learning System for Building Generalist
                  Models},
  journal      = {CoRR},
  volume       = {abs/2212.04408},
  year         = {2022},
  url          = {https://doi.org/10.48550/arXiv.2212.04408},
  doi          = {10.48550/arXiv.2212.04408},
  eprinttype    = {arXiv},
  eprint       = {2212.04408},
  timestamp    = {Mon, 02 Jan 2023 15:09:55 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2212-04408.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@misc{qwen1.5_110,
    title = {{Qwen1.5-110B}: The First {100B+} Model of the {Qwen1.5} Series},
    author = {{Qwen Team}},
    url = {https://qwenlm.github.io/blog/qwen1.5-110b/},
    year = 2024
}

@misc{rft,
      title={Scaling Relationship on Learning Mathematical Reasoning with Large Language Models}, 
      author={Zheng Yuan and Hongyi Yuan and Chengpeng Li and Guanting Dong and Keming Lu and Chuanqi Tan and Chang Zhou and Jingren Zhou},
      year={2023},
      eprint={2308.01825},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{lightman2023lets,
      title={Let's Verify Step by Step}, 
      author={Lightman, Hunter and Kosaraju, Vineet and Burda, Yura and Edwards, Harri and Baker, Bowen and Lee, Teddy and Leike, Jan and Schulman, John and Sutskever, Ilya and Cobbe, Karl},
      journal={CoRR},
  volume={abs/2305.20050},
      year={2023}
}

@inproceedings{math,
  author       = {Dan Hendrycks and
                  Collin Burns and
                  Saurav Kadavath and
                  Akul Arora and
                  Steven Basart and
                  Eric Tang and
                  Dawn Song and
                  Jacob Steinhardt},
  title        = {Measuring Mathematical Problem Solving With the {MATH} Dataset},
  booktitle    = {NeurIPS Datasets and Benchmarks},
  year         = {2021}
}

@article{math401,
  title={How well do Large Language Models perform in Arithmetic tasks?},
  author={Yuan, Zheng and Yuan, Hongyi and Tan, Chuanqi and Wang, Wei and Huang, Songfang},
  journal={CoRR},
  volume={abs/2304.02015},
  year={2023}
}

@inproceedings{Wang2017DeepNS,
  title={Deep Neural Solver for Math Word Problems},
  author={Yan Wang and Xiaojiang Liu and Shuming Shi},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  year={2017},
  url={https://api.semanticscholar.org/CorpusID:910689}
}

@article{coig,
  title={Chinese open instruction generalist: A preliminary release},
  author={Zhang, Ge and Shi, Yemin and Liu, Ruibo and Yuan, Ruibin and Li, Yizhi and Dong, Siwei and Shu, Yu and Li, Zhaoqun and Wang, Zekun and Lin, Chenghua and others},
  journal={CoRR},
  volume={abs/2304.07987},
  year={2023}
}

@misc{alpaca-cot,
  author = {Qingyi Si and Tong Wang and Naibin Gu and Rui Liu and Zheng Lin },
  insititution = {Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China},
  title = {{Alpaca-CoT}: An Instruction-Tuning Platform with Unified Interface of Instruction Collection, Parameter-efficient Methods, and Large Language Models},
  year = {2023},
  url = {https://github.com/PhoebusSi/alpaca-CoT},
}

@article{wizardmath,
  title={{WizardMath}: Empowering mathematical reasoning for large language models via reinforced evol-instruct},
  author={Luo, Haipeng and Sun, Qingfeng and Xu, Can and Zhao, Pu and Lou, Jianguang and Tao, Chongyang and Geng, Xiubo and Lin, Qingwei and Chen, Shifeng and Zhang, Dongmei},
  journal={CoRR},
  volume={abs/2308.09583},
  year={2023}
}

@article{azerbayev2023proofnet,
  title={{ProofNet}: Autoformalizing and formally proving undergraduate-level mathematics},
  author={Azerbayev, Zhangir and Piotrowski, Bartosz and Schoelkopf, Hailey and Ayers, Edward W and Radev, Dragomir and Avigad, Jeremy},
  journal={CoRR},
  volume={abs/2302.12433},
  year={2023}
}

@article{liu2023goat,
  title={Goat: Fine-tuned {LLaMA} Outperforms {GPT-4} on Arithmetic Tasks},
  author={Liu, Tiedong and Low, Bryan Kian Hsiang},
  journal={CoRR},
  volume={abs/2305.14201},
  year={2023}
}

@article{AlphaCode,
  author       = {Yujia Li and
                  David H. Choi and
                  Junyoung Chung and
                  Nate Kushman and
                  Julian Schrittwieser and
                  R{\'{e}}mi Leblond and
                  Tom Eccles and
                  James Keeling and
                  Felix Gimeno and
                  Agustin Dal Lago and
                  Thomas Hubert and
                  Peter Choy and
                  Cyprien de Masson d'Autume and
                  Igor Babuschkin and
                  Xinyun Chen and
                  Po{-}Sen Huang and
                  Johannes Welbl and
                  Sven Gowal and
                  Alexey Cherepanov and
                  James Molloy and
                  Daniel J. Mankowitz and
                  Esme Sutherland Robson and
                  Pushmeet Kohli and
                  Nando de Freitas and
                  Koray Kavukcuoglu and
                  Oriol Vinyals},
  title        = {Competition-Level Code Generation with {AlphaCode}},
  journal      = {CoRR},
  volume       = {abs/2203.07814},
  year         = {2022},
}

@article{LaMDA,
  author       = {Romal Thoppilan and
                  Daniel De Freitas and
                  Jamie Hall and
                  Noam Shazeer and
                  Apoorv Kulshreshtha and
                  Heng{-}Tze Cheng and
                  Alicia Jin and
                  Taylor Bos and
                  Leslie Baker and
                  Yu Du and
                  YaGuang Li and
                  Hongrae Lee and
                  Huaixiu Steven Zheng and
                  Amin Ghafouri and
                  Marcelo Menegali and
                  Yanping Huang and
                  Maxim Krikun and
                  Dmitry Lepikhin and
                  James Qin and
                  Dehao Chen and
                  Yuanzhong Xu and
                  Zhifeng Chen and
                  Adam Roberts and
                  Maarten Bosma and
                  Yanqi Zhou and
                  Chung{-}Ching Chang and
                  Igor Krivokon and
                  Will Rusch and
                  Marc Pickett and
                  Kathleen S. Meier{-}Hellstern and
                  Meredith Ringel Morris and
                  Tulsee Doshi and
                  Renelito Delos Santos and
                  Toju Duke and
                  Johnny Soraker and
                  Ben Zevenbergen and
                  Vinodkumar Prabhakaran and
                  Mark Diaz and
                  Ben Hutchinson and
                  Kristen Olson and
                  Alejandra Molina and
                  Erin Hoffman{-}John and
                  Josh Lee and
                  Lora Aroyo and
                  Ravi Rajakumar and
                  Alena Butryna and
                  Matthew Lamm and
                  Viktoriya Kuzmina and
                  Joe Fenton and
                  Aaron Cohen and
                  Rachel Bernstein and
                  Ray Kurzweil and
                  Blaise Ag{\"{u}}era y Arcas and
                  Claire Cui and
                  Marian Croak and
                  Ed H. Chi and
                  Quoc Le},
  title        = {{LaMDA}: Language Models for Dialog Applications},
  journal      = {CoRR},
  volume       = {abs/2201.08239},
  year         = {2022},
  url          = {https://arxiv.org/abs/2201.08239},
  eprinttype    = {arXiv},
  eprint       = {2201.08239},
}

@article{livecodebench,
  author       = {Naman Jain and
                  King Han and
                  Alex Gu and
                  Wen{-}Ding Li and
                  Fanjia Yan and
                  Tianjun Zhang and
                  Sida Wang and
                  Armando Solar{-}Lezama and
                  Koushik Sen and
                  Ion Stoica},
  title        = {{LiveCodeBench}: Holistic and Contamination Free Evaluation of Large
                  Language Models for Code},
  journal      = {CoRR},
  volume       = {abs/2403.07974},
  year         = {2024}
}

@article{codex,
  author       = {Mark Chen and
                  Jerry Tworek and
                  Heewoo Jun and
                  Qiming Yuan and
                  Henrique Pond{\'{e}} de Oliveira Pinto and
                  Jared Kaplan and
                  Harrison Edwards and
                  Yuri Burda and
                  Nicholas Joseph and
                  Greg Brockman and
                  Alex Ray and
                  Raul Puri and
                  Gretchen Krueger and
                  Michael Petrov and
                  Heidy Khlaaf and
                  Girish Sastry and
                  Pamela Mishkin and
                  Brooke Chan and
                  Scott Gray and
                  Nick Ryder and
                  Mikhail Pavlov and
                  Alethea Power and
                  Lukasz Kaiser and
                  Mohammad Bavarian and
                  Clemens Winter and
                  Philippe Tillet and
                  Felipe Petroski Such and
                  Dave Cummings and
                  Matthias Plappert and
                  Fotios Chantzis and
                  Elizabeth Barnes and
                  Ariel Herbert{-}Voss and
                  William Hebgen Guss and
                  Alex Nichol and
                  Alex Paino and
                  Nikolas Tezak and
                  Jie Tang and
                  Igor Babuschkin and
                  Suchir Balaji and
                  Shantanu Jain and
                  William Saunders and
                  Christopher Hesse and
                  Andrew N. Carr and
                  Jan Leike and
                  Joshua Achiam and
                  Vedant Misra and
                  Evan Morikawa and
                  Alec Radford and
                  Matthew Knight and
                  Miles Brundage and
                  Mira Murati and
                  Katie Mayer and
                  Peter Welinder and
                  Bob McGrew and
                  Dario Amodei and
                  Sam McCandlish and
                  Ilya Sutskever and
                  Wojciech Zaremba},
  title        = {Evaluating Large Language Models Trained on Code},
  journal      = {CoRR},
  volume       = {abs/2107.03374},
  year         = {2021},
  url          = {https://arxiv.org/abs/2107.03374},
  eprinttype    = {arXiv},
  eprint       = {2107.03374},
}
@misc{Azure,
  author = {Microsoft},
  insititution = {Microsoft},
  title = {Azure openai service models},
  year = {2023},
  url = {https://learn.microsoft.com/en-us/azure/
cognitive-services/openai/concepts/models},
}

@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford {Alpaca}: An Instruction-following {LLaMA} model},
  year = {2023},
  url = {https://github.com/tatsu-lab/stanford_alpaca},
}

@misc{codealpaca,
  author = {Sahil Chaudhary},
  title = {Code {Alpaca}: An Instruction-following {LLaMA} model for code generation},
  year = {2023},
  url = {https://github.com/sahil280114/codealpaca},
}

@article{lora,
  title={{LoRA}: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={CoRR},
  volume={abs/2106.09685},
  year={2021}
}

@article{chatdb,
  title={ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory},
  author={Hu, Chenxu and Fu, Jie and Du, Chenzhuang and Luo, Simian and Zhao, Junbo and Zhao, Hang},
  journal={CoRR},
  volume={abs/2306.03901},
  year={2023}
}

@article{memorybank,
  title={{MemoryBank}: Enhancing Large Language Models with Long-Term Memory},
  author={Zhong, Wanjun and Guo, Lianghong and Gao, Qiqi and Wang, Yanlin},
  journal={CoRR},
  volume={abs/2305.10250},
  year={2023}
}

@article{webgpt,
  title={{WebGPT}: Browser-assisted question-answering with human feedback},
  author={Nakano, Reiichiro and Hilton, Jacob and Balaji, Suchir and Wu, Jeff and Ouyang, Long and Kim, Christina and Hesse, Christopher and Jain, Shantanu and Kosaraju, Vineet and Saunders, William and others},
  journal={CoRR},
  volume={abs/2112.09332},
  year={2021}
}

@article{webglm,
  title={{WebGLM}: Towards An Efficient Web-Enhanced Question Answering System with Human Preferences},
  author={Liu, Xiao and Lai, Hanyu and Yu, Hao and Xu, Yifan and Zeng, Aohan and Du, Zhengxiao and Zhang, Peng and Dong, Yuxiao and Tang, Jie},
  journal={CoRR},
  volume={abs/2306.07906},
  year={2023}
}

@article{hugginggpt,
  title={{HuggingGPT}: Solving {AI} tasks with {ChatGPT} and its friends in {HuggingFace}},
  author={Shen, Yongliang and Song, Kaitao and Tan, Xu and Li, Dongsheng and Lu, Weiming and Zhuang, Yueting},
  journal={CoRR},
  volume={abs/2303.17580},
  year={2023}
}

@article{modelscope_agent,
  title={{ModelScope-Agent}: Building Your Customizable Agent System with Open-source Large Language Models},
  author={Li, Chenliang and Chen, Hehong and Yan, Ming and Shen, Weizhou and Xu, Haiyang and Wu, Zhikai and Zhang, Zhicheng and Zhou, Wenmeng and Chen, Yingda and Cheng, Chen and others},
  journal={CoRR},
  volume={abs/2309.00986},
  year={2023}
}

@article{qlora,
  title={{QLoRA}: Efficient finetuning of quantized {LLMs}},
  author={Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke},
  journal={CoRR},
  volume={abs/2305.14314},
  year={2023}
}

@article{agentverse,
  title={AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents},
  author={Chen, Weize and Su, Yusheng and Zuo, Jingwei and Yang, Cheng and Yuan, Chenfei and Qian, Chen and Chan, Chi-Min and Qin, Yujia and Lu, Yaxi and Xie, Ruobing and others},
  journal={CoRR},
  volume={abs/2308.10848},
  year={2023}
}

@article{camel,
  title={Camel: Communicative agents for ``mind'' exploration of large scale language model society},
  author={Li, Guohao and Hammoud, Hasan Abed Al Kader and Itani, Hani and Khizbullin, Dmitrii and Ghanem, Bernard},
  journal={CoRR},
  volume={abs/2303.17760},
  year={2023}
}

@article{voyager,
  title={Voyager: An open-ended embodied agent with large language models},
  author={Wang, Guanzhi and Xie, Yuqi and Jiang, Yunfan and Mandlekar, Ajay and Xiao, Chaowei and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
  journal={CoRR},
  volume={abs/2305.16291},
  year={2023}
}

@article{metagpt,
  title={Metagpt: Meta programming for multi-agent collaborative framework},
  author={Hong, Sirui and Zheng, Xiawu and Chen, Jonathan and Cheng, Yuheng and Zhang, Ceyao and Wang, Zili and Yau, Steven Ka Shing and Lin, Zijuan and Zhou, Liyang and Ran, Chenyu and others},
  journal={CoRR},
  volume={abs/2308.00352},
  year={2023}
}

@article{santacoder,
  title={{SantaCoder}: Don't reach for the stars!},
  author={Allal, Loubna Ben and Li, Raymond and Kocetkov, Denis and Mou, Chenghao and Akiki, Christopher and Ferrandis, Carlos Munoz and Muennighoff, Niklas and Mishra, Mayank and Gu, Alex and Dey, Manan and others},
  journal={CoRR},
  volume={abs/2301.03988},
  year={2023}
}

@article{palm-e,
  title={Palm-e: An embodied multimodal language model},
  author={Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and others},
  journal={CoRR},
  volume={abs/2303.03378},
  year={2023}
}

@article{incoder,
  title={InCoder: A Generative Model for Code Infilling and Synthesis},
  author={Daniel Fried and Armen Aghajanyan and Jessy Lin and Sida I. Wang and Eric Wallace and Freda Shi and Ruiqi Zhong and Wen-tau Yih and Luke Zettlemoyer and Mike Lewis},
  journal={ArXiv},
  year={2022},
  volume={abs/2204.05999}
}

@article{scratchpad,
  title={Show Your Work: Scratchpads for Intermediate Computation with Language Models},
  author={Maxwell Nye and Anders Andreassen and Guy Gur-Ari and Henryk Michalewski and Jacob Austin and David Bieber and David Dohan and Aitor Lewkowycz and Maarten Bosma and David Luan and Charles Sutton and Augustus Odena},
  journal={ArXiv},
  year={2021},
  volume={abs/2112.00114}
}

@article{self_consistency,
  title={Self-Consistency Improves Chain of Thought Reasoning in Language Models},
  author={Xuezhi Wang and Jason Wei and Dale Schuurmans and Quoc Le and Ed Huai-hsin Chi and Denny Zhou},
  journal={ArXiv},
  year={2022},
  volume={abs/2203.11171}
}

@article{least_to_most,
  title={Least-to-Most Prompting Enables Complex Reasoning in Large Language Models},
  author={Denny Zhou and Nathanael Scharli and Le Hou and Jason Wei and Nathan Scales and Xuezhi Wang and Dale Schuurmans and Olivier Bousquet and Quoc Le and Ed Huai-hsin Chi},
  journal={ArXiv},
  year={2022},
  volume={abs/2205.10625}
}

@article{codet5,
  title={{CodeT5}: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation},
  author={Wang, Yue and Wang, Weishi and Joty, Shafiq and Hoi, Steven CH},
  journal={CoRR},
  volume={abs/2109.00859},
  year={2021}
}

@article{werewolf,
  title={Exploring Large Language Models for Communication Games: An Empirical Study on Werewolf},
  author={Xu, Yuzhuang and Wang, Shuo and Li, Peng and Luo, Fuwen and Wang, Xiaolong and Liu, Weidong and Liu, Yang},
  journal={CoRR},
  volume={abs/2309.04658},
  year={2023}
}

@article{bnb,
  title={{LLM.int8()}: 8-bit Matrix Multiplication for Transformers at Scale},
  author={Dettmers, Tim and Lewis, Mike and Belkada, Younes and Zettlemoyer, Luke},
  journal={CoRR},
  volume={abs/2208.07339},
  year={2022}
}

@article{belle,
  title={Exploring the impact of instruction data scaling on large language models: An empirical study on real-world use cases},
  author={Ji, Yunjie and Deng, Yong and Gong, Yan and Peng, Yiping and Niu, Qiang and Zhang, Lei and Ma, Baochang and Li, Xiangang},
  journal={CoRR},
  volume={abs/2303.14742},
  year={2023}
}

@misc{vicuna,
    title = {Vicuna: An Open-Source Chatbot Impressing {GPT-4} with 90\%* {ChatGPT} Quality},
    url = {https://lmsys.org/blog/2023-03-30-vicuna/},
    author = {Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E. and Stoica, Ion and Xing, Eric P.},
    month = {March},
    year = {2023}
}

@article{tulu,
  title={How Far Can Camels Go? {Exploring} the State of Instruction Tuning on Open Resources},
  author={Wang, Yizhong and Ivison, Hamish and Dasigi, Pradeep and Hessel, Jack and Khot, Tushar and Chandu, Khyathi Raghavi and Wadden, David and MacMillan, Kelsey and Smith, Noah A and Beltagy, Iz and others},
  journal={CoRR},
  volume={abs/2306.04751},
  year={2023}
}

@misc{firefly,
  author = {Jianxin Yang},
  title = {Firefly},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/yangjianxin1/Firefly}},
}

@article{gptq,
  title={{GPTQ}: Accurate post-training quantization for generative pre-trained transformers},
  author={Frantar, Elias and Ashkboos, Saleh and Hoefler, Torsten and Alistarh, Dan},
  journal={CoRR},
  volume={abs/2210.17323},
  year={2022}
}

@inproceedings{pageattention,
  title={Efficient Memory Management for Large Language Model Serving with {PagedAttention}}, 
  author={Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph E. Gonzalez and Hao Zhang and Ion Stoica},
  booktitle={Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles},
  year={2023}
}

@article{rrhf,
  title={Rrhf: Rank responses to align language models with human feedback without tears},
  author={Yuan, Zheng and Yuan, Hongyi and Tan, Chuanqi and Wang, Wei and Huang, Songfang and Huang, Fei},
  journal={CoRR},
  volume={abs/2304.05302},
  year={2023}
}

@article{pro,
  title={Preference ranking optimization for human alignment},
  author={Song, Feifan and Yu, Bowen and Li, Minghao and Yu, Haiyang and Huang, Fei and Li, Yongbin and Wang, Houfeng},
  journal={CoRR},
  volume={abs/2306.17492},
  year={2023}
}

@misc{leetcode-solutions,
  author = {Eric Hartford},
title = {leetcode-solutions},
year = {2023},
url = {https://www.kaggle.com/datasets/erichartford/leetcode-solutions}
}

@misc{autogpt,
  author = {AutoGPT},
title = {{AutoGPT}: The heart of the open-source agent ecosystem},
year = {2023},
url = {https://github.com/Significant-Gravitas/Auto-GPT}
}

@misc{leetcode-solutions-python,
  author = {Le Vu Minh Huy},
title = {leetcode-solutions-python},
year = {2023},
url = {https://huggingface.co/datasets/mhhmm/leetcode-solutions-python}
}

@misc{evol,
author = {Nick Roshdieh},
title = {evol-teacher: Open Source {WizardCoder} Dataset},
year = {2023},
url = {https://github.com/nickrosh/evol-teacher}
}

@misc{codefuse-evol-instrution-66k,
author = {{CodeFuse}},
title = {{CodeFuse} Evol-Instruction-66k},
year = {2023},
url = {https://huggingface.co/datasets/codefuse-ai/Evol-instruction-66k}
}

@misc{codefuse-code-exercise-python-27k,
author = {{CodeFuse}},
title = {{CodeFuse} CodeExercise-Python-27k},
year = {2023},
url = {https://huggingface.co/datasets/codefuse-ai/CodeExercise-Python-27k}
}

@misc{TAL-SCQ5K-CN,
author={{MathGPT}},
title = {TAL-SCQ5K-CN Dataset},
year={2023},
url={https://www.mathgpt.com}
}

@inproceedings{codegen,
  author       = {Erik Nijkamp and
                  Bo Pang and
                  Hiroaki Hayashi and
                  Lifu Tu and
                  Huan Wang and
                  Yingbo Zhou and
                  Silvio Savarese and
                  Caiming Xiong},
  title        = {{CodeGen}: An Open Large Language Model for Code with Multi-Turn Program
                  Synthesis},
  booktitle    = {The Eleventh International Conference on Learning Representations,
                  {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023},
  publisher    = {OpenReview.net},
  year         = {2023},
}
@article{CodeGeeX,
  author       = {Qinkai Zheng and
                  Xiao Xia and
                  Xu Zou and
                  Yuxiao Dong and
                  Shan Wang and
                  Yufei Xue and
                  Zihan Wang and
                  Lei Shen and
                  Andi Wang and
                  Yang Li and
                  Teng Su and
                  Zhilin Yang and
                  Jie Tang},
  title        = {{CodeGeeX}: {A} Pre-Trained Model for Code Generation with Multilingual
                  Evaluations on HumanEval-X},
  journal      = {CoRR},
  volume       = {abs/2303.17568},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2303.17568},
  doi          = {10.48550/arXiv.2303.17568},
  eprinttype    = {arXiv},
  eprint       = {2303.17568},
}

@article{CodeT5+,
  author       = {Yue Wang and
                  Hung Le and
                  Akhilesh Deepak Gotmare and
                  Nghi D. Q. Bui and
                  Junnan Li and
                  Steven C. H. Hoi},
  title        = {{CodeT5+}: Open Code Large Language Models for Code Understanding and
                  Generation},
  journal      = {CoRR},
  volume       = {abs/2305.07922},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2305.07922},
  doi          = {10.48550/arXiv.2305.07922},
  eprinttype    = {arXiv},
  eprint       = {2305.07922},
}

@inproceedings{self_instruct,
  author       = {Yizhong Wang and
                  Yeganeh Kordi and
                  Swaroop Mishra and
                  Alisa Liu and
                  Noah A. Smith and
                  Daniel Khashabi and
                  Hannaneh Hajishirzi},
  editor       = {Anna Rogers and
                  Jordan L. Boyd{-}Graber and
                  Naoaki Okazaki},
  title        = {{Self-Instruct}: Aligning Language Models with Self-Generated Instructions},
  booktitle    = {Proceedings of the 61st Annual Meeting of the Association for Computational
                  Linguistics (Volume 1: Long Papers), {ACL} 2023, Toronto, Canada,
                  July 9-14, 2023},
  pages        = {13484--13508},
  publisher    = {Association for Computational Linguistics},
  year         = {2023},
  url          = {https://doi.org/10.18653/v1/2023.acl-long.754},
  doi          = {10.18653/v1/2023.acl-long.754},
  timestamp    = {Thu, 10 Aug 2023 12:35:44 +0200},
  biburl       = {https://dblp.org/rec/conf/acl/WangKMLSKH23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@article{Wei2022EmergentAO,
  title={Emergent Abilities of Large Language Models},
  author={Jason Wei and Yi Tay and Rishi Bommasani and Colin Raffel and Barret Zoph and Sebastian Borgeaud and Dani Yogatama and Maarten Bosma and Denny Zhou and Donald Metzler and Ed Huai-hsin Chi and Tatsunori Hashimoto and Oriol Vinyals and Percy Liang and Jeff Dean and William Fedus},
  journal={Trans. Mach. Learn. Res.},
  year={2022},
  volume={2022},
  url={https://api.semanticscholar.org/CorpusID:249674500}
}
@article{octopack,
  author       = {Niklas Muennighoff and
                  Qian Liu and
                  Armel Zebaze and
                  Qinkai Zheng and
                  Binyuan Hui and
                  Terry Yue Zhuo and
                  Swayam Singh and
                  Xiangru Tang and
                  Leandro von Werra and
                  Shayne Longpre},
  title        = {{OctoPack}: Instruction Tuning Code Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2308.07124},
  year         = {2023},
}

@misc{yuan2023rrhf,
      title={{RRHF}: Rank Responses to Align Language Models with Human Feedback without tears}, 
      author={Zheng Yuan and Hongyi Yuan and Chuanqi Tan and Wei Wang and Songfang Huang and Fei Huang},
      year={2023},
      eprint={2304.05302},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{ntk,
      title={{NTK}-Aware Scaled {RoPE} allows {LLaMA} models to have extended (8k+) context size without any fine-tuning and minimal perplexity degradation.}, 
      author={bloc97},
      year={2023},
      url={https://www.reddit.com/r/LocalLLaMA/comments/14lz7j5/ntkaware_scaled_rope_allows_llama_models_to_have/}
}

@inproceedings{logn_attn,
  title={Overcoming a Theoretical Limitation of Self-Attention},
  author={Chiang, David and Cholak, Peter},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={7654--7664},
  year={2022}
}

@article{window_attn,
  title={Longformer: The long-document transformer},
  author={Beltagy, Iz and Peters, Matthew E and Cohan, Arman},
  journal={CoRR},
  volume={abs/2004.05150},
  year={2020}
}

@misc{qkv_bias,
  title={The magical effect of the {Bias} term: {RoPE} + {Bias} = better length extrapolation},
  author={Jianlin Su},
  year={2023},
  url={https://spaces.ac.cn/archives/9577}
}




@article{wizardcoder,
  title={{WizardCoder}: Empowering Code Large Language Models with Evol-Instruct},
  author={Luo, Ziyang and Xu, Can and Zhao, Pu and Sun, Qingfeng and Geng, Xiubo and Hu, Wenxiang and Tao, Chongyang and Ma, Jing and Lin, Qingwei and Jiang, Daxin},
  journal={CoRR},
  volume={abs/2306.08568},
  year={2023}
}


@article{PMP,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={CoRR},
  volume={abs/2204.05862},
  year={2022}
}

@article{askell2021general,
  title={A general language assistant as a laboratory for alignment},
  author={Askell, Amanda and Bai, Yuntao and Chen, Anna and Drain, Dawn and Ganguli, Deep and Henighan, Tom and Jones, Andy and Joseph, Nicholas and Mann, Ben and DasSarma, Nova and others},
  journal={CoRR},
  volume={abs/2112.00861},
  year={2021}
}

@article{bert,
  title={{BERT}: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={CoRR},
  volume={abs/1810.04805},
  year={2018}
}

@article{ppo,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={CoRR},
  volume={abs/1707.06347},
  year={2017}
}

@article{learn-summary,
  title={Learning to summarize with human feedback},
  author={Stiennon, Nisan and Ouyang, Long and Wu, Jeffrey and Ziegler, Daniel and Lowe, Ryan and Voss, Chelsea and Radford, Alec and Amodei, Dario and Christiano, Paul F},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={3008--3021},
  year={2020}
}

@article{yao2022react,
  title={{ReAct}: Synergizing Reasoning and Acting in Language Models},
  author={Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  journal={CoRR},
  volume={abs/2210.03629},
  year={2022}
}

@article{yarn,
  author       = {Bowen Peng and
                  Jeffrey Quesnelle and
                  Honglu Fan and
                  Enrico Shippole},
  title        = {{YaRN}: Efficient Context Window Extension of Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2309.00071},
  year         = {2023}
}

@inproceedings{upcycle,
  author       = {Aran Komatsuzaki and
                  Joan Puigcerver and
                  James Lee{-}Thorp and
                  Carlos Riquelme Ruiz and
                  Basil Mustafa and
                  Joshua Ainslie and
                  Yi Tay and
                  Mostafa Dehghani and
                  Neil Houlsby},
  title        = {Sparse Upcycling: Training Mixture-of-Experts from Dense Checkpoints},
  booktitle    = {{ICLR}},
  publisher    = {OpenReview.net},
  year         = {2023}
}

@article{deepseekmoe,
  author       = {Damai Dai and
                  Chengqi Deng and
                  Chenggang Zhao and
                  R. X. Xu and
                  Huazuo Gao and
                  Deli Chen and
                  Jiashi Li and
                  Wangding Zeng and
                  Xingkai Yu and
                  Y. Wu and
                  Zhenda Xie and
                  Y. K. Li and
                  Panpan Huang and
                  Fuli Luo and
                  Chong Ruan and
                  Zhifang Sui and
                  Wenfeng Liang},
  title        = {{DeepSeekMoE}: Towards Ultimate Expert Specialization in Mixture-of-Experts
                  Language Models},
  journal      = {CoRR},
  volume       = {abs/2401.06066},
  year         = {2024}
}

@inproceedings{deepspeedmoe,
  author       = {Samyam Rajbhandari and
                  Conglong Li and
                  Zhewei Yao and
                  Minjia Zhang and
                  Reza Yazdani Aminabadi and
                  Ammar Ahmad Awan and
                  Jeff Rasley and
                  Yuxiong He},
  title        = {{DeepSpeed-MoE}: Advancing Mixture-of-Experts Inference and Training
                  to Power Next-Generation {AI} Scale},
  booktitle    = {{ICML}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {162},
  pages        = {18332--18346},
  publisher    = {{PMLR}},
  year         = {2022}
}

@article{qwen,
author       = {Jinze Bai and
                  Shuai Bai and
                  Yunfei Chu and
                  Zeyu Cui and
                  Kai Dang and
                  Xiaodong Deng and
                  Yang Fan and
                  Wenbin Ge and
                  Yu Han and
                  Fei Huang and
                  Binyuan Hui and
                  Luo Ji and
                  Mei Li and
                  Junyang Lin and
                  Runji Lin and
                  Dayiheng Liu and
                  Gao Liu and
                  Chengqiang Lu and
                  Keming Lu and
                  Jianxin Ma and
                  Rui Men and
                  Xingzhang Ren and
                  Xuancheng Ren and
                  Chuanqi Tan and
                  Sinan Tan and
                  Jianhong Tu and
                  Peng Wang and
                  Shijie Wang and
                  Wei Wang and
                  Shengguang Wu and
                  Benfeng Xu and
                  Jin Xu and
                  An Yang and
                  Hao Yang and
                  Jian Yang and
                  Shusheng Yang and
                  Yang Yao and
                  Bowen Yu and
                  Hongyi Yuan and
                  Zheng Yuan and
                  Jianwei Zhang and
                  Xingxuan Zhang and
                  Yichang Zhang and
                  Zhenru Zhang and
                  Chang Zhou and
                  Jingren Zhou and
                  Xiaohuan Zhou and
                  Tianhang Zhu},
  title        = {Qwen Technical Report},
  journal      = {CoRR},
  volume       = {abs/2309.16609},
  year         = {2023}
}

@inproceedings{gqa,
  author       = {Joshua Ainslie and
                  James Lee{-}Thorp and
                  Michiel de Jong and
                  Yury Zemlyanskiy and
                  Federico Lebr{\'{o}}n and
                  Sumit Sanghai},
  title        = {{GQA}: Training Generalized Multi-Query {Transformer} Models from Multi-Head
                  Checkpoints},
  booktitle    = {{EMNLP}},
  pages        = {4895--4901},
  publisher    = {Association for Computational Linguistics},
  year         = {2023}
}

@article{cot,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@misc{taylor2022galactica,
      title={Galactica: A Large Language Model for Science}, 
      author={Ross Taylor and Marcin Kardas and Guillem Cucurull and Thomas Scialom and Anthony Hartshorn and Elvis Saravia and Andrew Poulton and Viktor Kerkez and Robert Stojnic},
      year={2022},
      eprint={2211.09085},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{lewkowycz2022solving,
      title={Solving Quantitative Reasoning Problems with Language Models}, 
      author={Aitor Lewkowycz and Anders Andreassen and David Dohan and Ethan Dyer and Henryk Michalewski and Vinay Ramasesh and Ambrose Slone and Cem Anil and Imanol Schlag and Theo Gutman-Solo and Yuhuai Wu and Behnam Neyshabur and Guy Gur-Ari and Vedant Misra},
      year={2022},
      eprint={2206.14858},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{yue2023mammoth,
  title={{MAmmoTH}: Building Math Generalist Models through Hybrid Instruction Tuning},
  author={Yue, Xiang and Qu, Xingwei and Zhang, Ge and Fu, Yao and Huang, Wenhao and Sun, Huan and Su, Yu and Chen, Wenhu},
  journal={CoRR},
  volume={abs/2309.05653},
  year={2023}
}


@inproceedings{code_translation_compiler,
  author       = {Marc Szafraniec and
                  Baptiste Rozi{\`{e}}re and
                  Hugh Leather and
                  Patrick Labatut and
                  Fran{\c{c}}ois Charton and
                  Gabriel Synnaeve},
  title        = {Code Translation with Compiler Representations},
  booktitle    = {The Eleventh International Conference on Learning Representations,
                  {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023},
  publisher    = {OpenReview.net},
  year         = {2023},
  url          = {https://openreview.net/pdf?id=XomEU3eNeSQ},
  timestamp    = {Fri, 30 Jun 2023 14:55:53 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/SzafraniecRLLCS23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{repocoder,
  author       = {Fengji Zhang and
                  Bei Chen and
                  Yue Zhang and
                  Jin Liu and
                  Daoguang Zan and
                  Yi Mao and
                  Jian{-}Guang Lou and
                  Weizhu Chen},
  title        = {{RepoCoder}: Repository-Level Code Completion Through Iterative Retrieval
                  and Generation},
  journal      = {CoRR},
  volume       = {abs/2303.12570},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2303.12570},
  doi          = {10.48550/arXiv.2303.12570},
  eprinttype    = {arXiv},
  eprint       = {2303.12570},
  timestamp    = {Thu, 13 Apr 2023 17:40:16 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2303-12570.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{code_refinement,
  author       = {Yue Liu and
                  Thanh Le{-}Cong and
                  Ratnadira Widyasari and
                  Chakkrit Tantithamthavorn and
                  Li Li and
                  Xuan{-}Bach Dinh Le and
                  David Lo},
  title        = {Refining {ChatGPT}-Generated Code: Characterizing and Mitigating Code
                  Quality Issues},
  journal      = {CoRR},
  volume       = {abs/2307.12596},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2307.12596},
  doi          = {10.48550/arXiv.2307.12596},
  eprinttype    = {arXiv},
  eprint       = {2307.12596},
  timestamp    = {Tue, 01 Aug 2023 14:49:51 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2307-12596.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{code_qa,
  author       = {Chenxiao Liu and
                  Xiaojun Wan},
  editor       = {Marie{-}Francine Moens and
                  Xuanjing Huang and
                  Lucia Specia and
                  Scott Wen{-}tau Yih},
  title        = {{CodeQA}: {A} Question Answering Dataset for Source Code Comprehension},
  booktitle    = {Findings of the Association for Computational Linguistics: {EMNLP}
                  2021, Virtual Event / Punta Cana, Dominican Republic, 16-20 November,
                  2021},
  pages        = {2618--2632},
  publisher    = {Association for Computational Linguistics},
  year         = {2021},
  url          = {https://doi.org/10.18653/v1/2021.findings-emnlp.223},
  doi          = {10.18653/v1/2021.findings-emnlp.223},
  timestamp    = {Thu, 20 Jan 2022 10:02:06 +0100},
  biburl       = {https://dblp.org/rec/conf/emnlp/Liu021.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@misc{logn_su,
  title={Improving Transformer: Length Extrapolation Ability and Position Robustness},
  author={Jianlin Su},
  year={2023},
  url={https://spaces.ac.cn/archives/9444}
}


@article{code_search_net,
  author       = {Hamel Husain and
                  Ho{-}Hsiang Wu and
                  Tiferet Gazit and
                  Miltiadis Allamanis and
                  Marc Brockschmidt},
  title        = {CodeSearchNet Challenge: Evaluating the State of Semantic Code Search},
  journal      = {CoRR},
  volume       = {abs/1909.09436},
  year         = {2019},
  url          = {http://arxiv.org/abs/1909.09436},
  eprinttype    = {arXiv},
  eprint       = {1909.09436},
  timestamp    = {Tue, 24 Sep 2019 11:33:51 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1909-09436.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}



@article{agieval,
  author       = {Wanjun Zhong and
                  Ruixiang Cui and
                  Yiduo Guo and
                  Yaobo Liang and
                  Shuai Lu and
                  Yanlin Wang and
                  Amin Saied and
                  Weizhu Chen and
                  Nan Duan},
  title        = {{AGIEval}: {A} Human-Centric Benchmark for Evaluating Foundation Models},
  journal      = {CoRR},
  volume       = {abs/2304.06364},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2304.06364},
  doi          = {10.48550/arXiv.2304.06364},
  eprinttype    = {arXiv},
  eprint       = {2304.06364},
  timestamp    = {Wed, 19 Apr 2023 12:42:23 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2304-06364.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}




@article{gaokao-bench,
  author       = {Xiaotian Zhang and
                  Chunyang Li and
                  Yi Zong and
                  Zhengyu Ying and
                  Liang He and
                  Xipeng Qiu},
  title        = {Evaluating the Performance of Large Language Models on {GAOKAO} Benchmark},
  journal      = {CoRR},
  volume       = {abs/2305.12474},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2305.12474},
  doi          = {10.48550/arXiv.2305.12474},
  eprinttype    = {arXiv},
  eprint       = {2305.12474},
  timestamp    = {Fri, 26 May 2023 11:29:33 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2305-12474.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}



@article{arc,
  author       = {Peter Clark and
                  Isaac Cowhey and
                  Oren Etzioni and
                  Tushar Khot and
                  Ashish Sabharwal and
                  Carissa Schoenick and
                  Oyvind Tafjord},
  title        = {Think you have Solved Question Answering? {Try} {ARC}, the {AI2} Reasoning
                  Challenge},
  journal      = {CoRR},
  volume       = {abs/1803.05457},
  year         = {2018}
}



@inproceedings{boolq,
  author       = {Christopher Clark and
                  Kenton Lee and
                  Ming{-}Wei Chang and
                  Tom Kwiatkowski and
                  Michael Collins and
                  Kristina Toutanova},
  editor       = {Jill Burstein and
                  Christy Doran and
                  Thamar Solorio},
  title        = {BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions},
  booktitle    = {Proceedings of the 2019 Conference of the North American Chapter of
                  the Association for Computational Linguistics: Human Language Technologies,
                  {NAACL-HLT} 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long
                  and Short Papers)},
  pages        = {2924--2936},
  publisher    = {Association for Computational Linguistics},
  year         = {2019},
  url          = {https://doi.org/10.18653/v1/n19-1300},
  doi          = {10.18653/v1/n19-1300},
  timestamp    = {Tue, 16 Aug 2022 23:04:27 +0200},
  biburl       = {https://dblp.org/rec/conf/naacl/ClarkLCK0T19.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}



@inproceedings{commonsenseqa,
  author       = {Alon Talmor and
                  Jonathan Herzig and
                  Nicholas Lourie and
                  Jonathan Berant},
  editor       = {Jill Burstein and
                  Christy Doran and
                  Thamar Solorio},
  title        = {{CommonsenseQA}: {A} Question Answering Challenge Targeting Commonsense
                  Knowledge},
  booktitle    = {Proceedings of the 2019 Conference of the North American Chapter of
                  the Association for Computational Linguistics: Human Language Technologies,
                  {NAACL-HLT} 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long
                  and Short Papers)},
  pages        = {4149--4158},
  publisher    = {Association for Computational Linguistics},
  year         = {2019},
  url          = {https://doi.org/10.18653/v1/n19-1421},
  doi          = {10.18653/v1/n19-1421},
  timestamp    = {Fri, 06 Aug 2021 00:41:31 +0200},
  biburl       = {https://dblp.org/rec/conf/naacl/TalmorHLB19.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}




@article{naturalquestions,
  author       = {Tom Kwiatkowski and
                  Jennimaria Palomaki and
                  Olivia Redfield and
                  Michael Collins and
                  Ankur P. Parikh and
                  Chris Alberti and
                  Danielle Epstein and
                  Illia Polosukhin and
                  Jacob Devlin and
                  Kenton Lee and
                  Kristina Toutanova and
                  Llion Jones and
                  Matthew Kelcey and
                  Ming{-}Wei Chang and
                  Andrew M. Dai and
                  Jakob Uszkoreit and
                  Quoc Le and
                  Slav Petrov},
  title        = {Natural Questions: a Benchmark for Question Answering Research},
  journal      = {Trans. Assoc. Comput. Linguistics},
  volume       = {7},
  pages        = {452--466},
  year         = {2019},
  url          = {https://doi.org/10.1162/tacl\_a\_00276},
  doi          = {10.1162/tacl\_a\_00276},
  timestamp    = {Tue, 16 Aug 2022 23:05:11 +0200},
  biburl       = {https://dblp.org/rec/journals/tacl/KwiatkowskiPRCP19.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{pmlr-v162-ethayarajh22a,
  title = 	 {Understanding Dataset Difficulty with $\mathcal{V}$-Usable Information},
  author =       {Ethayarajh, Kawin and Choi, Yejin and Swayamdipta, Swabha},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {5988--6008},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher = {PMLR},
}



@inproceedings{lambada,
  author       = {Denis Paperno and
                  Germ{\'{a}}n Kruszewski and
                  Angeliki Lazaridou and
                  Quan Ngoc Pham and
                  Raffaella Bernardi and
                  Sandro Pezzelle and
                  Marco Baroni and
                  Gemma Boleda and
                  Raquel Fern{\'{a}}ndez},
  title        = {The {LAMBADA} dataset: Word prediction requiring a broad discourse
                  context},
  booktitle    = {Proceedings of the 54th Annual Meeting of the Association for Computational
                  Linguistics, {ACL} 2016, August 7-12, 2016, Berlin, Germany, Volume
                  1: Long Papers},
  publisher    = {The Association for Computer Linguistics},
  year         = {2016},
  url          = {https://doi.org/10.18653/v1/p16-1144},
  doi          = {10.18653/v1/p16-1144},
  timestamp    = {Fri, 06 Aug 2021 00:41:02 +0200},
  biburl       = {https://dblp.org/rec/conf/acl/PapernoKLPBPBBF16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}



@inproceedings{ocnli,
  author       = {Hai Hu and
                  Kyle Richardson and
                  Liang Xu and
                  Lu Li and
                  Sandra K{\"{u}}bler and
                  Lawrence S. Moss},
  editor       = {Trevor Cohn and
                  Yulan He and
                  Yang Liu},
  title        = {{OCNLI:} Original Chinese Natural Language Inference},
  booktitle    = {Findings of the Association for Computational Linguistics: {EMNLP}
                  2020, Online Event, 16-20 November 2020},
  series       = {Findings of {ACL}},
  volume       = {{EMNLP} 2020},
  pages        = {3512--3526},
  publisher    = {Association for Computational Linguistics},
  year         = {2020},
  url          = {https://doi.org/10.18653/v1/2020.findings-emnlp.314},
  doi          = {10.18653/v1/2020.findings-emnlp.314},
  timestamp    = {Wed, 23 Mar 2022 10:11:55 +0100},
  biburl       = {https://dblp.org/rec/conf/emnlp/HuRXLKM20.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}



@inproceedings{hellaswag,
  author       = {Rowan Zellers and
                  Ari Holtzman and
                  Yonatan Bisk and
                  Ali Farhadi and
                  Yejin Choi},
  title        = {{HellaSwag}: Can a Machine Really Finish Your Sentence?},
  booktitle    = {{ACL} {(1)}},
  pages        = {4791--4800},
  publisher    = {Association for Computational Linguistics},
  year         = {2019}
}



@inproceedings{piqa,
  author       = {Yonatan Bisk and
                  Rowan Zellers and
                  Ronan Le Bras and
                  Jianfeng Gao and
                  Yejin Choi},
  title        = {{PIQA:} Reasoning about Physical Commonsense in Natural Language},
  booktitle    = {The Thirty-Fourth {AAAI} Conference on Artificial Intelligence, {AAAI}
                  2020, The Thirty-Second Innovative Applications of Artificial Intelligence
                  Conference, {IAAI} 2020, The Tenth {AAAI} Symposium on Educational
                  Advances in Artificial Intelligence, {EAAI} 2020, New York, NY, USA,
                  February 7-12, 2020},
  pages        = {7432--7439},
  publisher    = {{AAAI} Press},
  year         = {2020},
  url          = {https://doi.org/10.1609/aaai.v34i05.6239},
  doi          = {10.1609/aaai.v34i05.6239},
  timestamp    = {Mon, 04 Sep 2023 16:50:23 +0200},
  biburl       = {https://dblp.org/rec/conf/aaai/BiskZLGC20.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{arena-hard,
      title={From Crowdsourced Data to High-Quality Benchmarks: {Arena-Hard} and {BenchBuilder} Pipeline}, 
      author={Tianle Li and Wei-Lin Chiang and Evan Frick and Lisa Dunlap and Tianhao Wu and Banghua Zhu and Joseph E. Gonzalez and Ion Stoica},
      year={2024},
      journal={CoRR},
      volume={abs/2406.11939}
}

@article{mixeval,
  title={{MixEval}: Deriving Wisdom of the Crowd from {LLM} Benchmark Mixtures},
  author={Ni, Jinjie and Xue, Fuzhao and Yue, Xiang and Deng, Yuntian and Shah, Mahir and Jain, Kabir and Neubig, Graham and You, Yang},
  journal={CoRR}, 
  volume={abs/2406.06565},
  year={2024}
}

@article{alignbench,
  author       = {Xiao Liu and
                  Xuanyu Lei and
                  Shengyuan Wang and
                  Yue Huang and
                  Zhuoer Feng and
                  Bosi Wen and
                  Jiale Cheng and
                  Pei Ke and
                  Yifan Xu and
                  Weng Lam Tam and
                  Xiaohan Zhang and
                  Lichao Sun and
                  Hongning Wang and
                  Jing Zhang and
                  Minlie Huang and
                  Yuxiao Dong and
                  Jie Tang},
  title        = {{AlignBench}: Benchmarking {Chinese} Alignment of Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2311.18743},
  year         = {2023}
}


@article{siqa,
  author       = {Maarten Sap and
                  Hannah Rashkin and
                  Derek Chen and
                  Ronan Le Bras and
                  Yejin Choi},
  title        = {{SocialIQA}: Commonsense Reasoning about Social Interactions},
  journal      = {CoRR},
  volume       = {abs/1904.09728},
  year         = {2019},
  url          = {http://arxiv.org/abs/1904.09728},
  eprinttype    = {arXiv},
  eprint       = {1904.09728},
  timestamp    = {Sat, 29 Apr 2023 10:09:27 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1904-09728.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}



@misc{abel,
  author = {Chern, Ethan and Zou, Haoyang and Li, Xuefeng and Hu, Jiewen and Feng, Kehua and Li, Junlong and Liu, Pengfei},
  title = {Generative AI for Math: Abel},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/GAIR-NLP/abel}},
}

@misc{yu2023metamath,
      title={MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models}, 
      author={Longhui Yu and Weisen Jiang and Han Shi and Jincheng Yu and Zhengying Liu and Yu Zhang and James T. Kwok and Zhenguo Li and Adrian Weller and Weiyang Liu},
      year={2023},
      eprint={2309.12284},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{chern2023factool,
  title={FacTool: Factuality Detection in Generative AI--A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios},
  author={Chern, I and Chern, Steffi and Chen, Shiqi and Yuan, Weizhe and Feng, Kehua and Zhou, Chunting and He, Junxian and Neubig, Graham and Liu, Pengfei and others},
  journal={CoRR},
  volume={abs/2307.13528},
  year={2023}
}

@article{position_interpolation,
  title={Extending context window of large language models via positional interpolation},
  author={Chen, Shouyuan and Wong, Sherman and Chen, Liangjian and Tian, Yuandong},
  journal={CoRR},
  volume={abs/2306.15595},
  year={2023}
}

@inproceedings{evalplus,
  author       = {Jiawei Liu and
                  Chunqiu Steven Xia and
                  Yuyao Wang and
                  Lingming Zhang},
  title        = {Is Your Code Generated by {ChatGPT} Really Correct? {Rigorous} Evaluation
                  of Large Language Models for Code Generation},
  booktitle    = {NeurIPS},
  year         = {2023}
}

@article{chunkllama,
  author       = {Chenxin An and
                  Fei Huang and
                  Jun Zhang and
                  Shansan Gong and
                  Xipeng Qiu and
                  Chang Zhou and
                  Lingpeng Kong},
  title        = {Training-Free Long-Context Scaling of Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2402.17463},
  year         = {2024}
}


@article{ropeabf,
  author       = {Wenhan Xiong and
                  Jingyu Liu and
                  Igor Molybog and
                  Hejia Zhang and
                  Prajjwal Bhargava and
                  Rui Hou and
                  Louis Martin and
                  Rashi Rungta and
                  Karthik Abinav Sankararaman and
                  Barlas Oguz and
                  Madian Khabsa and
                  Han Fang and
                  Yashar Mehdad and
                  Sharan Narang and
                  Kshitiz Malik and
                  Angela Fan and
                  Shruti Bhosale and
                  Sergey Edunov and
                  Mike Lewis and
                  Sinong Wang and
                  Hao Ma},
  title        = {Effective Long-Context Scaling of Foundation Models},
  journal      = {CoRR},
  volume       = {abs/2309.16039},
  year         = {2023}
}

@inproceedings{koto-etal-2023-indommlu,
  author       = {Fajri Koto and
                  Nurul Aisyah and
                  Haonan Li and
                  Timothy Baldwin},
  title        = {Large Language Models Only Pass Primary School Exams in {Indonesia}:
                  {A} Comprehensive Test on {IndoMMLU}},
  booktitle    = {{EMNLP}},
  pages        = {12359--12374},
  publisher    = {Association for Computational Linguistics},
  year         = {2023}
}

@article{revaut2024how,
  author       = {Mathieu Ravaut and
                  Bosheng Ding and
                  Fangkai Jiao and
                  Hailin Chen and
                  Xingxuan Li and
                  Ruochen Zhao and
                  Chengwei Qin and
                  Caiming Xiong and
                  Shafiq Joty},
  title        = {How Much are {LLMs} Contaminated? {A} Comprehensive Survey and the LLMSanitize
                  Library},
  journal      = {CoRR},
  volume       = {abs/2404.00699},
  year         = {2024}
}

@inproceedings{sainz2023nlp,
  author       = {Oscar Sainz and
                  Jon Ander Campos and
                  Iker Garc{\'{\i}}a{-}Ferrero and
                  Julen Etxaniz and
                  Oier Lopez de Lacalle and
                  Eneko Agirre},
  title        = {{NLP} Evaluation in trouble: On the Need to Measure {LLM} Data Contamination
                  for each Benchmark},
  booktitle    = {{EMNLP} (Findings)},
  pages        = {10776--10787},
  publisher    = {Association for Computational Linguistics},
  year         = {2023}
}

@inproceedings{golchin2024time,
  author       = {Shahriar Golchin and
                  Mihai Surdeanu},
  title        = {Time Travel in LLMs: Tracing Data Contamination in Large Language
                  Models},
  booktitle    = {{ICLR}},
  publisher    = {OpenReview.net},
  year         = {2024}
}

@article{rummlu-mera,
  author       = {Alena Fenogenova and
                  Artem Chervyakov and
                  Nikita Martynov and
                  Anastasia Kozlova and
                  Maria Tikhonova and
                  Albina Akhmetgareeva and
                  Anton A. Emelyanov and
                  Denis Shevelev and
                  Pavel Lebedev and
                  Leonid Sinev and
                  Ulyana Isaeva and
                  Katerina Kolomeytseva and
                  Daniil Moskovskiy and
                  Elizaveta Goncharova and
                  Nikita Savushkin and
                  Polina Mikhailova and
                  Denis Dimitrov and
                  Alexander Panchenko and
                  Sergey Markov},
  title        = {{MERA:} {A} Comprehensive {LLM} Evaluation in Russian},
  journal      = {CoRR},
  volume       = {abs/2401.04531},
  year         = {2024}
}

@article{belebele,
  author       = {Lucas Bandarkar and
                  Davis Liang and
                  Benjamin Muller and
                  Mikel Artetxe and
                  Satya Narayan Shukla and
                  Donald Husa and
                  Naman Goyal and
                  Abhinandan Krishnan and
                  Luke Zettlemoyer and
                  Madian Khabsa},
  title        = {The {Belebele} Benchmark: A Parallel Reading Comprehension Dataset in
                  122 Language Variants},
  journal      = {CoRR},
  volume       = {abs/2308.16884},
  year         = {2023}
}

@inproceedings{xcopa,
  author       = {Edoardo Maria Ponti and
                  Goran Glavas and
                  Olga Majewska and
                  Qianchu Liu and
                  Ivan Vulic and
                  Anna Korhonen},
  title        = {{XCOPA}: {A} Multilingual Dataset for Causal Commonsense Reasoning},
  booktitle    = {{EMNLP} {(1)}},
  pages        = {2362--2376},
  publisher    = {Association for Computational Linguistics},
  year         = {2020}
}

@inproceedings{xstory_cloze,
      author       = {Xi Victoria Lin and
                  Todor Mihaylov and
                  Mikel Artetxe and
                  Tianlu Wang and
                  Shuohui Chen and
                  Daniel Simig and
                  Myle Ott and
                  Naman Goyal and
                  Shruti Bhosale and
                  Jingfei Du and
                  Ramakanth Pasunuru and
                  Sam Shleifer and
                  Punit Singh Koura and
                  Vishrav Chaudhary and
                  Brian O'Horo and
                  Jeff Wang and
                  Luke Zettlemoyer and
                  Zornitsa Kozareva and
                  Mona T. Diab and
                  Veselin Stoyanov and
                  Xian Li},
  title        = {Few-shot Learning with Multilingual Generative Language Models},
  booktitle    = {{EMNLP}},
  pages        = {9019--9052},
  publisher    = {Association for Computational Linguistics},
  year         = {2022}
}

@inproceedings{paws-x,
      author       = {Yinfei Yang and
                  Yuan Zhang and
                  Chris Tar and
                  Jason Baldridge},
  title        = {{PAWS-X:} {A} Cross-lingual Adversarial Dataset for Paraphrase Identification},
  booktitle    = {{EMNLP/IJCNLP} {(1)}},
  pages        = {3685--3690},
  publisher    = {Association for Computational Linguistics},
  year         = {2019}
}

@misc{msift,
author = {Chen, Zhihong and Yan, Shuo and Liang, Juhao and Jiang, Feng and Wu, Xiangbo and Yu, Fei and Chen, Guiming Hardy and Chen, Junying and Zhang, Hongbo and Li Jianquan and Wan Xiang and Wang, Benyou},
title = {{MultilingualSIFT}: Multilingual Supervised Instruction Fine-tuning},
url = {https://github.com/FreedomIntelligence/MultilingualSIFT},
year = {2023}
}

@inproceedings{mgsm,
  author       = {Freda Shi and
                  Mirac Suzgun and
                  Markus Freitag and
                  Xuezhi Wang and
                  Suraj Srivats and
                  Soroush Vosoughi and
                  Hyung Won Chung and
                  Yi Tay and
                  Sebastian Ruder and
                  Denny Zhou and
                  Dipanjan Das and
                  Jason Wei},
  title        = {Language models are multilingual chain-of-thought reasoners},
  booktitle    = {The Eleventh International Conference on Learning Representations,
                  {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023},
  publisher    = {OpenReview.net},
  year         = {2023},
  url          = {https://openreview.net/pdf?id=fR3wGCk-IXp},
  timestamp    = {Fri, 30 Jun 2023 14:55:53 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/ShiSF0SVCTRZ0W23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@article{flores,
  author       = {Naman Goyal and
                  Cynthia Gao and
                  Vishrav Chaudhary and
                  Peng{-}Jen Chen and
                  Guillaume Wenzek and
                  Da Ju and
                  Sanjana Krishnan and
                  Marc'Aurelio Ranzato and
                  Francisco Guzm{\'{a}}n and
                  Angela Fan},
  title        = {The {Flores-101} Evaluation Benchmark for Low-Resource and Multilingual
                  Machine Translation},
  journal      = {Trans. Assoc. Comput. Linguistics},
  volume       = {10},
  pages        = {522--538},
  year         = {2022}
}

@techreport{claude3,
  title={The {Claude} 3 model family: {Opus}, {Sonnet}, {Haiku}},
  author={Anthropic},
  institution={{Anthropic, AI}},
  url={https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model\_Card\_Claude\_3.pdf},
  year={2024}
}



@article{arena,
  author       = {Wei{-}Lin Chiang and
                  Lianmin Zheng and
                  Ying Sheng and
                  Anastasios Nikolas Angelopoulos and
                  Tianle Li and
                  Dacheng Li and
                  Hao Zhang and
                  Banghua Zhu and
                  Michael I. Jordan and
                  Joseph E. Gonzalez and
                  Ion Stoica},
  title        = {Chatbot Arena: An Open Platform for Evaluating {LLMs} by Human Preference},
  journal      = {CoRR},
  volume       = {abs/2403.04132},
  year         = {2024}
}

@article{llama3,
  author       = {Abhimanyu Dubey and
                  Abhinav Jauhri and
                  Abhinav Pandey and
                  Abhishek Kadian and
                  Ahmad Al{-}Dahle and
                  Aiesha Letman and
                  Akhil Mathur and
                  Alan Schelten and
                  Amy Yang and
                  Angela Fan and
                  Anirudh Goyal and
                  Anthony Hartshorn and
                  Aobo Yang and
                  Archi Mitra and
                  Archie Sravankumar and
                  Artem Korenev and
                  Arthur Hinsvark and
                  Arun Rao and
                  Aston Zhang and
                  Aur{\'{e}}lien Rodriguez and
                  Austen Gregerson and
                  Ava Spataru and
                  Baptiste Rozi{\`{e}}re and
                  Bethany Biron and
                  Binh Tang and
                  Bobbie Chern and
                  Charlotte Caucheteux and
                  Chaya Nayak and
                  Chloe Bi and
                  Chris Marra and
                  Chris McConnell and
                  Christian Keller and
                  Christophe Touret and
                  Chunyang Wu and
                  Corinne Wong and
                  Cristian Canton Ferrer and
                  Cyrus Nikolaidis and
                  Damien Allonsius and
                  Daniel Song and
                  Danielle Pintz and
                  Danny Livshits and
                  David Esiobu and
                  Dhruv Choudhary and
                  Dhruv Mahajan and
                  Diego Garcia{-}Olano and
                  Diego Perino and
                  Dieuwke Hupkes and
                  Egor Lakomkin and
                  Ehab AlBadawy and
                  Elina Lobanova and
                  Emily Dinan and
                  Eric Michael Smith and
                  Filip Radenovic and
                  Frank Zhang and
                  Gabriel Synnaeve and
                  Gabrielle Lee and
                  Georgia Lewis Anderson and
                  Graeme Nail and
                  Gr{\'{e}}goire Mialon and
                  Guan Pang and
                  Guillem Cucurell and
                  Hailey Nguyen and
                  Hannah Korevaar and
                  Hu Xu and
                  Hugo Touvron and
                  Iliyan Zarov and
                  Imanol Arrieta Ibarra and
                  Isabel M. Kloumann and
                  Ishan Misra and
                  Ivan Evtimov and
                  Jade Copet and
                  Jaewon Lee and
                  Jan Geffert and
                  Jana Vranes and
                  Jason Park and
                  Jay Mahadeokar and
                  Jeet Shah and
                  Jelmer van der Linde and
                  Jennifer Billock and
                  Jenny Hong and
                  Jenya Lee and
                  Jeremy Fu and
                  Jianfeng Chi and
                  Jianyu Huang and
                  Jiawen Liu and
                  Jie Wang and
                  Jiecao Yu and
                  Joanna Bitton and
                  Joe Spisak and
                  Jongsoo Park and
                  Joseph Rocca and
                  Joshua Johnstun and
                  Joshua Saxe and
                  Junteng Jia and
                  Kalyan Vasuden Alwala and
                  Kartikeya Upasani and
                  Kate Plawiak and
                  Ke Li and
                  Kenneth Heafield and
                  Kevin Stone and
                  et al.},
  title        = {The {Llama} 3 Herd of Models},
  journal      = {CoRR},
  volume       = {abs/2407.21783},
  year         = {2024}
}

@article{mistral,
  author       = {Albert Q. Jiang and
                  Alexandre Sablayrolles and
                  Arthur Mensch and
                  Chris Bamford and
                  Devendra Singh Chaplot and
                  Diego de Las Casas and
                  Florian Bressand and
                  Gianna Lengyel and
                  Guillaume Lample and
                  Lucile Saulnier and
                  L{\'{e}}lio Renard Lavaud and
                  Marie{-}Anne Lachaux and
                  Pierre Stock and
                  Teven Le Scao and
                  Thibaut Lavril and
                  Thomas Wang and
                  Timoth{\'{e}}e Lacroix and
                  William El Sayed},
  title        = {Mistral {7B}},
  journal      = {CoRR},
  volume       = {abs/2310.06825},
  year         = {2023}
}

@article{mixtral,
  author       = {Albert Q. Jiang and
                  Alexandre Sablayrolles and
                  Antoine Roux and
                  Arthur Mensch and
                  Blanche Savary and
                  Chris Bamford and
                  Devendra Singh Chaplot and
                  Diego de Las Casas and
                  Emma Bou Hanna and
                  Florian Bressand and
                  Gianna Lengyel and
                  Guillaume Bour and
                  Guillaume Lample and
                  L{\'{e}}lio Renard Lavaud and
                  Lucile Saulnier and
                  Marie{-}Anne Lachaux and
                  Pierre Stock and
                  Sandeep Subramanian and
                  Sophia Yang and
                  Szymon Antoniak and
                  Teven Le Scao and
                  Th{\'{e}}ophile Gervet and
                  Thibaut Lavril and
                  Thomas Wang and
                  Timoth{\'{e}}e Lacroix and
                  William El Sayed},
  title        = {Mixtral of Experts},
  journal      = {CoRR},
  volume       = {abs/2401.04088},
  year         = {2024}
}

@techreport{gemini,
  title = {Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context},
  author = {{Gemini Team}},
  institution = {Google},
  url = {https://storage.googleapis.com/deepmind-media/gemini/gemini\_v1\_5\_report.pdf},
  year = {2024}
}

@article{gemma,
  author       = {Thomas Mesnard and Cassidy Hardin and Robert Dadashi and Surya Bhupatiraju and Shreya Pathak and Laurent Sifre and Morgane Rivière and Mihir Sanjay Kale and Juliette Love and Pouya Tafti and Léonard Hussenot and Pier Giuseppe Sessa and Aakanksha Chowdhery and Adam Roberts and Aditya Barua and Alex Botev and Alex Castro-Ros and Ambrose Slone and Amélie Héliou and Andrea Tacchetti and Anna Bulanova and Antonia Paterson and Beth Tsai and Bobak Shahriari and Charline Le Lan and Christopher A. Choquette-Choo and Clément Crepy and Daniel Cer and Daphne Ippolito and David Reid and Elena Buchatskaya and Eric Ni and Eric Noland and Geng Yan and George Tucker and George-Christian Muraru and Grigory Rozhdestvenskiy and Henryk Michalewski and Ian Tenney and Ivan Grishchenko and Jacob Austin and James Keeling and Jane Labanowski and Jean-Baptiste Lespiau and Jeff Stanway and Jenny Brennan and Jeremy Chen and Johan Ferret and Justin Chiu and Justin Mao-Jones and Katherine Lee and Kathy Yu and Katie Millican and Lars Lowe Sjoesund and Lisa Lee and Lucas Dixon and Machel Reid and Maciej Mikuła and Mateo Wirth and Michael Sharman and Nikolai Chinaev and Nithum Thain and Olivier Bachem and Oscar Chang and Oscar Wahltinez and Paige Bailey and Paul Michel and Petko Yotov and Rahma Chaabouni and Ramona Comanescu and Reena Jana and Rohan Anil and Ross McIlroy and Ruibo Liu and Ryan Mullins and Samuel L Smith and Sebastian Borgeaud and Sertan Girgin and Sholto Douglas and Shree Pandya and Siamak Shakeri and Soham De and Ted Klimenko and Tom Hennigan and Vlad Feinberg and Wojciech Stokowiec and Yu-hui Chen and Zafarali Ahmed and Zhitao Gong and Tris Warkentin and Ludovic Peran and Minh Giang and Clément Farabet and Oriol Vinyals and Jeff Dean and Koray Kavukcuoglu and Demis Hassabis and Zoubin Ghahramani and Douglas Eck and Joelle Barral and Fernando Pereira and Eli Collins and Armand Joulin and Noah Fiedel and Evan Senter and Alek Andreev and Kathleen Kenealy},
  title        = {Gemma: Open Models Based on {Gemini} Research and Technology},
  journal      = {CoRR},
  volume       = {abs/2403.08295},
  year         = {2024}
}

@article{deepseek,
author       = {Aixin Liu and
                  Bei Feng and
                  Bin Wang and
                  Bingxuan Wang and
                  Bo Liu and
                  Chenggang Zhao and
                  Chengqi Deng and
                  Chong Ruan and
                  Damai Dai and
                  Daya Guo and
                  Dejian Yang and
                  Deli Chen and
                  Dongjie Ji and
                  Erhang Li and
                  Fangyun Lin and
                  Fuli Luo and
                  Guangbo Hao and
                  Guanting Chen and
                  Guowei Li and
                  Hao Zhang and
                  Hanwei Xu and
                  Hao Yang and
                  Haowei Zhang and
                  Honghui Ding and
                  Huajian Xin and
                  Huazuo Gao and
                  Hui Li and
                  Hui Qu and
                  J. L. Cai and
                  Jian Liang and
                  Jianzhong Guo and
                  Jiaqi Ni and
                  Jiashi Li and
                  Jin Chen and
                  Jingyang Yuan and
                  Junjie Qiu and
                  Junxiao Song and
                  Kai Dong and
                  Kaige Gao and
                  Kang Guan and
                  Lean Wang and
                  Lecong Zhang and
                  Lei Xu and
                  Leyi Xia and
                  Liang Zhao and
                  Liyue Zhang and
                  Meng Li and
                  Miaojun Wang and
                  Mingchuan Zhang and
                  Minghua Zhang and
                  Minghui Tang and
                  Mingming Li and
                  Ning Tian and
                  Panpan Huang and
                  Peiyi Wang and
                  Peng Zhang and
                  Qihao Zhu and
                  Qinyu Chen and
                  Qiushi Du and
                  R. J. Chen and
                  R. L. Jin and
                  Ruiqi Ge and
                  Ruizhe Pan and
                  Runxin Xu and
                  Ruyi Chen and
                  S. S. Li and
                  Shanghao Lu and
                  Shangyan Zhou and
                  Shanhuang Chen and
                  Shaoqing Wu and
                  Shengfeng Ye and
                  Shirong Ma and
                  Shiyu Wang and
                  Shuang Zhou and
                  Shuiping Yu and
                  Shunfeng Zhou and
                  Size Zheng and
                  Tao Wang and
                  Tian Pei and
                  Tian Yuan and
                  Tianyu Sun and
                  W. L. Xiao and
                  Wangding Zeng and
                  Wei An and
                  Wen Liu and
                  Wenfeng Liang and
                  Wenjun Gao and
                  Wentao Zhang and
                  X. Q. Li and
                  Xiangyue Jin and
                  Xianzu Wang and
                  Xiao Bi and
                  Xiaodong Liu and
                  Xiaohan Wang and
                  Xiaojin Shen and
                  Xiaokang Chen and
                  Xiaosha Chen and
                  Xiaotao Nie and
                  Xiaowen Sun},
  title        = {{DeepSeek-V2}: A Strong, Economical, and Efficient Mixture-of-Experts
                  Language Model},
  journal      = {CoRR},
  volume       = {abs/2405.04434},
  year         = {2024}
}

@article{yi,
author       = {Alex Young and
                  Bei Chen and
                  Chao Li and
                  Chengen Huang and
                  Ge Zhang and
                  Guanwei Zhang and
                  Heng Li and
                  Jiangcheng Zhu and
                  Jianqun Chen and
                  Jing Chang and
                  Kaidong Yu and
                  Peng Liu and
                  Qiang Liu and
                  Shawn Yue and
                  Senbin Yang and
                  Shiming Yang and
                  Tao Yu and
                  Wen Xie and
                  Wenhao Huang and
                  Xiaohui Hu and
                  Xiaoyi Ren and
                  Xinyao Niu and
                  Pengcheng Nie and
                  Yuchi Xu and
                  Yudong Liu and
                  Yue Wang and
                  Yuxuan Cai and
                  Zhenyu Gu and
                  Zhiyuan Liu and
                  Zonghong Dai},
  title        = {Yi: Open Foundation Models by {01.AI}},
  journal      = {CoRR},
  volume       = {abs/2403.04652},
  year         = {2024}
}

@misc{dbrx,
  title = {Introducing {DBRX}: A New State-of-the-Art Open {LLM}},
  author = {{Mosaic Research Team}},
  url = {https://www.databricks.com/blog/introducing-dbrx-new-state-art-open-llm},
  year = {2024}
}

@article{qwenaudio,
  author       = {Yunfei Chu and
                  Jin Xu and
                  Xiaohuan Zhou and
                  Qian Yang and
                  Shiliang Zhang and
                  Zhijie Yan and
                  Chang Zhou and
                  Jingren Zhou},
  title        = {{Qwen-Audio}: Advancing Universal Audio Understanding via Unified Large-Scale
                  Audio-Language Models},
  journal      = {CoRR},
  volume       = {abs/2311.07919},
  year         = {2023}
}

@inproceedings{mtbench,
  author       = {Lianmin Zheng and
                  Wei{-}Lin Chiang and
                  Ying Sheng and
                  Siyuan Zhuang and
                  Zhanghao Wu and
                  Yonghao Zhuang and
                  Zi Lin and
                  Zhuohan Li and
                  Dacheng Li and
                  Eric P. Xing and
                  Hao Zhang and
                  Joseph E. Gonzalez and
                  Ion Stoica},
  title        = {Judging {LLM}-as-a-Judge with {MT-Bench} and {Chatbot Arena}},
  booktitle    = {NeurIPS},
  year         = {2023}
}

@article{humaneval,
  author       = {Mark Chen and
                  Jerry Tworek and
                  Heewoo Jun and
                  Qiming Yuan and
                  Henrique Pond{\'{e}} de Oliveira Pinto and
                  Jared Kaplan and
                  Harrison Edwards and
                  Yuri Burda and
                  Nicholas Joseph and
                  Greg Brockman and
                  Alex Ray and
                  Raul Puri and
                  Gretchen Krueger and
                  Michael Petrov and
                  Heidy Khlaaf and
                  Girish Sastry and
                  Pamela Mishkin and
                  Brooke Chan and
                  Scott Gray and
                  Nick Ryder and
                  Mikhail Pavlov and
                  Alethea Power and
                  Lukasz Kaiser and
                  Mohammad Bavarian and
                  Clemens Winter and
                  Philippe Tillet and
                  Felipe Petroski Such and
                  Dave Cummings and
                  Matthias Plappert and
                  Fotios Chantzis and
                  Elizabeth Barnes and
                  Ariel Herbert{-}Voss and
                  William Hebgen Guss and
                  Alex Nichol and
                  Alex Paino and
                  Nikolas Tezak and
                  Jie Tang and
                  Igor Babuschkin and
                  Suchir Balaji and
                  Shantanu Jain and
                  William Saunders and
                  Christopher Hesse and
                  Andrew N. Carr and
                  Jan Leike and
                  Joshua Achiam and
                  Vedant Misra and
                  Evan Morikawa and
                  Alec Radford and
                  Matthew Knight and
                  Miles Brundage and
                  Mira Murati and
                  Katie Mayer and
                  Peter Welinder and
                  Bob McGrew and
                  Dario Amodei and
                  Sam McCandlish and
                  Ilya Sutskever and
                  Wojciech Zaremba},
  title        = {Evaluating Large Language Models Trained on Code},
  journal      = {CoRR},
  volume       = {abs/2107.03374},
  year         = {2021}
}

@article{gpqa,
  author       = {David Rein and
                  Betty Li Hou and
                  Asa Cooper Stickland and
                  Jackson Petty and
                  Richard Yuanzhe Pang and
                  Julien Dirani and
                  Julian Michael and
                  Samuel R. Bowman},
  title        = {{GPQA}: A Graduate-Level {Google}-Proof {Q}{\&}{A} Benchmark},
  journal      = {CoRR},
  volume       = {abs/2311.12022},
  year         = {2023}
}

@inproceedings{theoremqa,
  author       = {Wenhu Chen and
                  Ming Yin and
                  Max Ku and
                  Pan Lu and
                  Yixin Wan and
                  Xueguang Ma and
                  Jianyu Xu and
                  Xinyi Wang and
                  Tony Xia},
  title        = {{TheoremQA}: A Theorem-driven Question Answering Dataset},
  booktitle    = {{EMNLP}},
  pages        = {7889--7901},
  publisher    = {Association for Computational Linguistics},
  year         = {2023}
}

@article{alpacaeval,
  author       = {Yann Dubois and
                  Bal{\'{a}}zs Galambosi and
                  Percy Liang and
                  Tatsunori B. Hashimoto},
  title        = {Length-Controlled AlpacaEval: {A} Simple Way to Debias Automatic Evaluators},
  journal      = {CoRR},
  volume       = {abs/2404.04475},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2404.04475},
  doi          = {10.48550/ARXIV.2404.04475},
  eprinttype    = {arXiv},
  eprint       = {2404.04475},
  timestamp    = {Wed, 15 May 2024 08:47:08 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2404-04475.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{ifeval,
  author       = {Jeffrey Zhou and
                  Tianjian Lu and
                  Swaroop Mishra and
                  Siddhartha Brahma and
                  Sujoy Basu and
                  Yi Luan and
                  Denny Zhou and
                  Le Hou},
  title        = {Instruction-Following Evaluation for Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2311.07911},
  year         = {2023}
}

@article{multiple,
  author       = {Federico Cassano and
                  John Gouwar and
                  Daniel Nguyen and
                  Sydney Nguyen and
                  Luna Phipps{-}Costin and
                  Donald Pinckney and
                  Ming{-}Ho Yee and
                  Yangtian Zi and
                  Carolyn Jane Anderson and
                  Molly Q. Feldman and
                  Arjun Guha and
                  Michael Greenberg and
                  Abhinav Jangda},
  title        = {{MultiPL-E}: {A} Scalable and Polyglot Approach to Benchmarking Neural
                  Code Generation},
  journal      = {{IEEE} Trans. Software Eng.},
  volume       = {49},
  number       = {7},
  pages        = {3675--3691},
  year         = {2023}
}

@article{mmlupro,
  author       = {Yubo Wang and
                  Xueguang Ma and
                  Ge Zhang and
                  Yuansheng Ni and
                  Abhranil Chandra and
                  Shiguang Guo and
                  Weiming Ren and
                  Aaran Arulraj and
                  Xuan He and
                  Ziyan Jiang and
                  Tianle Li and
                  Max Ku and
                  Kai Wang and
                  Alex Zhuang and
                  Rongqi Fan and
                  Xiang Yue and
                  Wenhu Chen},
  title        = {{MMLU-Pro}: {A} More Robust and Challenging Multi-Task Language Understanding
                  Benchmark},
  journal      = {CoRR},
  volume       = {abs/2406.01574},
  year         = {2024}
}

@article{winogrande,
  author       = {Keisuke Sakaguchi and
                  Ronan Le Bras and
                  Chandra Bhagavatula and
                  Yejin Choi},
  title        = {{WinoGrande}: An adversarial winograd schema challenge at scale},
  journal      = {Commun. {ACM}},
  volume       = {64},
  number       = {9},
  pages        = {99--106},
  year         = {2021}
}

@inproceedings{truthfulqa,
  author       = {Stephanie Lin and
                  Jacob Hilton and
                  Owain Evans},
  title        = {{TruthfulQA}: Measuring How Models Mimic Human Falsehoods},
  booktitle    = {{ACL} {(1)}},
  pages        = {3214--3252},
  publisher    = {Association for Computational Linguistics},
  year         = {2022}
}

@article{jamba,
  author       = {Opher Lieber and
                  Barak Lenz and
                  Hofit Bata and
                  Gal Cohen and
                  Jhonathan Osin and
                  Itay Dalmedigos and
                  Erez Safahi and
                  Shaked Meirom and
                  Yonatan Belinkov and
                  Shai Shalev{-}Shwartz and
                  Omri Abend and
                  Raz Alon and
                  Tomer Asida and
                  Amir Bergman and
                  Roman Glozman and
                  Michael Gokhman and
                  Avashalom Manevich and
                  Nir Ratner and
                  Noam Rozen and
                  Erez Shwartz and
                  Mor Zusman and
                  Yoav Shoham},
  title        = {Jamba: A Hybrid {Transformer-Mamba} Language Model},
  journal      = {CoRR},
  volume       = {abs/2403.19887},
  year         = {2024}
}

@misc{codeqwen,
      title={{Code with CodeQwen1.5}}, 
      author={{Qwen Team}},
      year={2024},
      url={https://qwenlm.github.io/blog/codeqwen1.5/}
}

@misc{phi2,
      title={Phi-2: The surprising power of small language models}, 
      author={Marah Abdin and Jyoti Aneja and Sebastien Bubeck and Caio César Teodoro Mendes and Weizhu Chen and Allie Del Giorno and Ronen Eldan and Sivakanth Gopi and Suriya Gunasekar and Mojan Javaheripi and Piero Kauffmann and Yin Tat Lee and Yuanzhi Li and Anh Nguyen and Gustavo de Rosa and Olli Saarikivi and Adil Salim and Shital Shah and Michael Santacroce and Harkirat Singh Behl and Adam Taumann Kalai and Xin Wang and Rachel Ward and Philipp Witte and Cyril Zhang and Yi Zhang},
      year={2024},
      url={https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/}
}

@article{minicpm,
  author       = {Shengding Hu and
                  Yuge Tu and
                  Xu Han and
                  Chaoqun He and
                  Ganqu Cui and
                  Xiang Long and
                  Zhi Zheng and
                  Yewei Fang and
                  Yuxiang Huang and
                  Weilin Zhao and
                  Xinrong Zhang and
                  Zhen Leng Thai and
                  Kai Zhang and
                  Chongyi Wang and
                  Yuan Yao and
                  Chenyang Zhao and
                  Jie Zhou and
                  Jie Cai and
                  Zhongwu Zhai and
                  Ning Ding and
                  Chao Jia and
                  Guoyang Zeng and
                  Dahai Li and
                  Zhiyuan Liu and
                  Maosong Sun},
  title        = {{MiniCPM}: Unveiling the Potential of Small Language Models with Scalable
                  Training Strategies},
  journal      = {CoRR},
  volume       = {abs/2404.06395},
  year         = {2024}
}

@article{phi3,
  author       = {Marah I Abdin and
                  Sam Ade Jacobs and
                  Ammar Ahmad Awan and
                  Jyoti Aneja and
                  Ahmed Awadallah and
                  Hany Awadalla and
                  Nguyen Bach and
                  Amit Bahree and
                  Arash Bakhtiari and
                  Harkirat S. Behl and
                  Alon Benhaim and
                  Misha Bilenko and
                  Johan Bjorck and
                  S{\'{e}}bastien Bubeck and
                  Martin Cai and
                  Caio C{\'{e}}sar Teodoro Mendes and
                  Weizhu Chen and
                  Vishrav Chaudhary and
                  Parul Chopra and
                  Allie Del Giorno and
                  Gustavo de Rosa and
                  Matthew Dixon and
                  Ronen Eldan and
                  Dan Iter and
                  Amit Garg and
                  Abhishek Goswami and
                  Suriya Gunasekar and
                  Emman Haider and
                  Junheng Hao and
                  Russell J. Hewett and
                  Jamie Huynh and
                  Mojan Javaheripi and
                  Xin Jin and
                  Piero Kauffmann and
                  Nikos Karampatziakis and
                  Dongwoo Kim and
                  Mahoud Khademi and
                  Lev Kurilenko and
                  James R. Lee and
                  Yin Tat Lee and
                  Yuanzhi Li and
                  Chen Liang and
                  Weishung Liu and
                  Eric Lin and
                  Zeqi Lin and
                  Piyush Madan and
                  Arindam Mitra and
                  Hardik Modi and
                  Anh Nguyen and
                  Brandon Norick and
                  Barun Patra and
                  Daniel Perez{-}Becker and
                  Thomas Portet and
                  Reid Pryzant and
                  Heyang Qin and
                  Marko Radmilac and
                  Corby Rosset and
                  Sambudha Roy and
                  Olatunji Ruwase and
                  Olli Saarikivi and
                  Amin Saied and
                  Adil Salim and
                  Michael Santacroce and
                  Shital Shah and
                  Ning Shang and
                  Hiteshi Sharma and
                  Xia Song and
                  Masahiro Tanaka and
                  Xin Wang and
                  Rachel Ward and
                  Guanhua Wang and
                  Philipp Witte and
                  Michael Wyatt and
                  Can Xu and
                  Jiahang Xu and
                  Sonali Yadav and
                  Fan Yang and
                  Ziyi Yang and
                  Donghan Yu and
                  Chengruidong Zhang and
                  Cyril Zhang and
                  Jianwen Zhang and
                  Li Lyna Zhang and
                  Yi Zhang and
                  Yue Zhang and
                  Yunan Zhang and
                  Xiren Zhou},
  title        = {Phi-3 Technical Report: {A} Highly Capable Language Model Locally
                  on Your Phone},
  journal      = {CoRR},
  volume       = {abs/2404.14219},
  year         = {2024}
}

@misc{niah,
      title={Needle in a haystack - Pressure testing {LLMs}}, 
      author={Gregory Kamradt},
      year={2023},
      url={https://github.com/gkamradt/LLMTest_NeedleInAHaystack}
}

@article{yuan2024lveval,
  author       = {Tao Yuan and
                  Xuefei Ning and
                  Dong Zhou and
                  Zhijie Yang and
                  Shiyao Li and
                  Minghui Zhuang and
                  Zheyue Tan and
                  Zhuyu Yao and
                  Dahua Lin and
                  Boxun Li and
                  Guohao Dai and
                  Shengen Yan and
                  Yu Wang},
  title        = {{LV-Eval}: {A} Balanced Long-Context Benchmark with 5 Length Levels
                  Up to {256K}},
  journal      = {CoRR},
  volume       = {abs/2402.05136},
  year         = {2024}
}

@article{chatglm4,
    title={{ChatGLM}: A Family of Large Language Models from {GLM-130B} to {GLM-4} All Tools},
    author={Aohan Zeng and Bin Xu and Bowen Wang and Chenhui Zhang and Da Yin and Diego Rojas and Guanyu Feng and Hanlin Zhao and Hanyu Lai and Hao Yu and Hongning Wang and Jiadai Sun and Jiajie Zhang and Jiale Cheng and Jiayi Gui and Jie Tang and Jing Zhang and Juanzi Li and Lei Zhao and Lindong Wu and Lucen Zhong and Mingdao Liu and Minlie Huang and Peng Zhang and Qinkai Zheng and Rui Lu and Shuaiqi Duan and Shudan Zhang and Shulin Cao and Shuxun Yang and Weng Lam Tam and Wenyi Zhao and Xiao Liu and Xiao Xia and Xiaohan Zhang and Xiaotao Gu and Xin Lv and Xinghan Liu and Xinyi Liu and Xinyue Yang and Xixuan Song and Xunkai Zhang and Yifan An and Yifan Xu and Yilin Niu and Yuantao Yang and Yueyan Li and Yushi Bai and Yuxiao Dong and Zehan Qi and Zhaoyu Wang and Zhen Yang and Zhengxiao Du and Zhenyu Hou and Zihan Wang},
  journal      = {CoRR},
  volume       = {abs/2406.12793},
  year         = {2024}
}

@inproceedings{wang2020neural,
  author       = {Changhan Wang and
                  Kyunghyun Cho and
                  Jiatao Gu},
  title        = {Neural Machine Translation with Byte-Level Subwords},
  booktitle    = {{AAAI}},
  pages        = {9154--9160},
  publisher    = {{AAAI} Press},
  year         = {2020}
}

@inproceedings{sennirch2016neural,
  author       = {Rico Sennrich and
                  Barry Haddow and
                  Alexandra Birch},
  title        = {Neural Machine Translation of Rare Words with Subword Units},
  booktitle    = {{ACL} {(1)}},
  publisher    = {The Association for Computer Linguistics},
  year         = {2016}
}

@article{hsieh2024ruler,
  title={{RULER}: What's the Real Context Size of Your Long-Context Language Models?},
  author={Cheng-Ping Hsieh and Simeng Sun and Samuel Kriman and Shantanu Acharya and Dima Rekesh and Fei Jia and Yang Zhang and Boris Ginsburg},
  year={2024},
  journal={CoRR},
  volume={abs/2404.06654},
}



@inproceedings{longalign2024bai,
  author       = {Yushi Bai and
                  Xin Lv and
                  Jiajie Zhang and
                  Yuze He and
                  Ji Qi and
                  Lei Hou and
                  Jie Tang and
                  Yuxiao Dong and
                  Juanzi Li},
  title        = {{LongAlign}: {A} Recipe for Long Context Alignment of Large Language
                  Models},
  booktitle    = {{EMNLP} (Findings)},
  pages        = {1376--1395},
  publisher    = {Association for Computational Linguistics},
  year         = {2024}
}

@article{livebench,
  author    = {Colin White and
                  Samuel Dooley and
                  Manley Roberts and
                  Arka Pal and
                  Benjamin Feuer and
                  Siddhartha Jain and
                  Ravid Shwartz{-}Ziv and
                  Neel Jain and
                  Khalid Saifullah and
                  Siddartha Naidu and
                  Chinmay Hegde and
                  Yann LeCun and
                  Tom Goldstein and
                  Willie Neiswanger and
                  Micah Goldblum},
  title     = {{LiveBench}: A Challenging, Contamination-Free {LLM} Benchmark},
  year      = {2024},
  journal   = {CoRR},
  volume    = {abs/2406.19314}
}

@article{blend,
  author       = {Junho Myung and
                  Nayeon Lee and
                  Yi Zhou and
                  Jiho Jin and
                  Rifki Afina Putri and
                  Dimosthenis Antypas and
                  Hsuvas Borkakoty and
                  Eunsu Kim and
                  Carla P{\'{e}}rez{-}Almendros and
                  Abinew Ali Ayele and
                  V{\'{\i}}ctor Guti{\'{e}}rrez{-}Basulto and
                  Yazm{\'{\i}}n Ib{\'{a}}{\~{n}}ez{-}Garc{\'{\i}}a and
                  Hwaran Lee and
                  Shamsuddeen Hassan Muhammad and
                  Ki{-}Woong Park and
                  Anar Sabuhi Rzayev and
                  Nina White and
                  Seid Muhie Yimam and
                  Mohammad Taher Pilehvar and
                  Nedjma Ousidhoum and
                  Jos{\'{e}} Camacho{-}Collados and
                  Alice Oh},
  title        = {BLEnD: {A} Benchmark for LLMs on Everyday Knowledge in Diverse Cultures and Languages},
  year         = {2024},
  journal      = {CoRR},
  volume       = {abs/2406.09948}
}

@article{jiang2024minference,
    title={MInference 1.0: Accelerating Pre-filling for Long-Context LLMs via Dynamic Sparse Attention},
    author={Jiang, Huiqiang and Li, Yucheng and Zhang, Chengruidong and Wu, Qianhui and Luo, Xufang and Ahn, Surin and Han, Zhenhua and Abdi, Amir H and Li, Dongsheng and Lin, Chin-Yew and Yang, Yuqing and Qiu, Lili},
    journal={arXiv preprint arXiv:2407.02490},
    year={2024}
}